{"ast":null,"code":"var _jsxFileName = \"/Users/yuvvan_talreja/Desktop/Coding/agentic-research/src/App.js\";\nimport React, { useState, useEffect, useRef } from 'react';\nimport { Alert } from '@/components/ui/alert';\nimport { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend } from 'recharts';\n\n// Neural Network for each agent\nclass AgentNetwork {\n  constructor(inputSize, hiddenSize, outputSize) {\n    this.weights1 = new Array(inputSize).fill(0).map(() => new Array(hiddenSize).fill(0).map(() => Math.random() * 2 - 1));\n    this.weights2 = new Array(hiddenSize).fill(0).map(() => new Array(outputSize).fill(0).map(() => Math.random() * 2 - 1));\n  }\n  forward(inputs) {\n    // Simple feedforward network with ReLU activation\n    const hidden = inputs.map((_, i) => this.weights1[i].reduce((sum, w, j) => sum + w * inputs[j], 0)).map(x => Math.max(0, x));\n    const outputs = this.weights2.map(row => hidden.reduce((sum, h, j) => sum + h * row[j], 0)).map(x => 1 / (1 + Math.exp(-x))); // Sigmoid for output\n\n    return outputs;\n  }\n}\nclass Agent {\n  constructor(x, y, id) {\n    this.x = x;\n    this.y = y;\n    this.id = id;\n    this.energy = 100;\n    this.message = new Array(4).fill(0); // 4-bit message vector\n    this.network = new AgentNetwork(12, 8, 6); // Input: position(2), energy(1), resources nearby(5), message received(4)\n    // Output: movement(2), action(2), message(2)\n    this.reward = 0;\n    this.memory = [];\n  }\n  act(state) {\n    const outputs = this.network.forward(state);\n    return {\n      dx: outputs[0] * 2 - 1,\n      // Movement in x (-1 to 1)\n      dy: outputs[1] * 2 - 1,\n      // Movement in y (-1 to 1)\n      action: outputs.slice(2, 4),\n      // Action probabilities\n      message: outputs.slice(4, 6).map(x => x > 0.5 ? 1 : 0) // Binary message bits\n    };\n  }\n  learn(experience) {\n    this.memory.push(experience);\n    // Implement Q-learning or policy gradient here\n    // For now, we'll use a simple reward accumulation\n    this.reward += experience.reward;\n  }\n}\nclass Resource {\n  constructor(x, y, value) {\n    this.x = x;\n    this.y = y;\n    this.value = value;\n  }\n}\nconst MARLSimulation = () => {\n  const canvasRef = useRef(null);\n  const agentsRef = useRef([]);\n  const resourcesRef = useRef([]);\n  const animationFrameRef = useRef(null);\n  const [isRunning, setIsRunning] = useState(false);\n  const [metrics, setMetrics] = useState([{\n    timestamp: Date.now(),\n    averageReward: 0,\n    resourceConflicts: 0,\n    cooperativeActions: 0,\n    messageEntropy: 0\n  }]);\n  const [settings, setSettings] = useState({\n    numAgents: 10,\n    numResources: 20,\n    learningRate: 0.01,\n    explorationRate: 0.1,\n    communicationRange: 50,\n    resourceRegenerationRate: 0.01\n  });\n\n  // Initialize simulation\n  const initializeSimulation = () => {\n    const canvas = canvasRef.current;\n\n    // Initialize agents\n    const newAgents = [];\n    for (let i = 0; i < settings.numAgents; i++) {\n      newAgents.push(new Agent(Math.random() * canvas.width, Math.random() * canvas.height, i));\n    }\n    agentsRef.current = newAgents;\n\n    // Initialize resources\n    const newResources = [];\n    for (let i = 0; i < settings.numResources; i++) {\n      newResources.push(new Resource(Math.random() * canvas.width, Math.random() * canvas.height, Math.random() * 50 + 50));\n    }\n    resourcesRef.current = newResources;\n  };\n\n  // Calculate state for an agent\n  const getAgentState = agent => {\n    const nearbyResources = resourcesRef.current.filter(r => distance(agent, r) < settings.communicationRange).slice(0, 5).map(r => distance(agent, r) / settings.communicationRange);\n    const nearbyAgents = agentsRef.current.filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n    const receivedMessage = nearbyAgents.length > 0 ? nearbyAgents[0].message : [0, 0, 0, 0];\n    return [agent.x / canvasRef.current.width, agent.y / canvasRef.current.height, agent.energy / 100, ...nearbyResources, ...new Array(5 - nearbyResources.length).fill(1), ...receivedMessage];\n  };\n\n  // Update simulation state\n  const updateSimulation = () => {\n    const canvas = canvasRef.current;\n    const updatedAgents = agentsRef.current.map(agent => {\n      const state = getAgentState(agent);\n      const action = agent.act(state);\n\n      // Update position\n      const newX = (agent.x + action.dx * 5 + canvas.width) % canvas.width;\n      const newY = (agent.y + action.dy * 5 + canvas.height) % canvas.height;\n\n      // Check for resources\n      const nearbyResources = resourcesRef.current.filter(r => distance({\n        x: newX,\n        y: newY\n      }, r) < 10);\n      let reward = 0;\n      if (nearbyResources.length > 0) {\n        const resource = nearbyResources[0];\n        const competingAgents = agentsRef.current.filter(a => a !== agent && distance({\n          x: newX,\n          y: newY\n        }, resource) < 10);\n        if (competingAgents.length > 0) {\n          // Resource competition scenario\n          const totalAgents = competingAgents.length + 1;\n          reward = resource.value / totalAgents;\n\n          // Encourage cooperation through communication\n          const cooperativeAgents = competingAgents.filter(a => a.message.some(bit => bit === 1));\n          if (cooperativeAgents.length > 0) {\n            reward *= 1.5; // Bonus for cooperative behavior\n          }\n        } else {\n          reward = resource.value;\n        }\n        resource.value *= 1 - 0.5; // Deplete resource\n        if (resource.value < 10) {\n          resourcesRef.current = resourcesRef.current.filter(r => r !== resource);\n        }\n      }\n\n      // Update agent\n      agent.x = newX;\n      agent.y = newY;\n      agent.energy = Math.min(100, agent.energy + reward);\n      agent.message = action.message;\n\n      // Learn from experience\n      agent.learn({\n        state,\n        action,\n        reward,\n        nextState: getAgentState(agent)\n      });\n      return agent;\n    });\n\n    // Regenerate resources\n    if (Math.random() < settings.resourceRegenerationRate && resourcesRef.current.length < settings.numResources) {\n      resourcesRef.current.push(new Resource(Math.random() * canvas.width, Math.random() * canvas.height, Math.random() * 50 + 50));\n    }\n    agentsRef.current = updatedAgents;\n\n    // Update metrics\n    if (Date.now() % 10 === 0) {\n      const newMetrics = calculateMetrics();\n      setMetrics(prev => [...prev.slice(-50), newMetrics]);\n    }\n  };\n\n  // Calculate simulation metrics\n  const calculateMetrics = () => {\n    const agents = agentsRef.current;\n\n    // Calculate average reward\n    const averageReward = agents.reduce((sum, agent) => sum + agent.reward, 0) / agents.length;\n\n    // Count resource conflicts\n    const resourceConflicts = resourcesRef.current.reduce((count, resource) => {\n      const nearbyAgents = agents.filter(a => distance(a, resource) < 10);\n      return count + (nearbyAgents.length > 1 ? 1 : 0);\n    }, 0);\n\n    // Count cooperative actions (agents sharing resources when communicating)\n    const cooperativeActions = agents.reduce((count, agent) => {\n      const nearbyAgents = agents.filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n      return count + (nearbyAgents.some(a => a.message.some(bit => bit === 1)) ? 1 : 0);\n    }, 0);\n\n    // Calculate message entropy (measure of communication diversity)\n    const messages = agents.map(a => a.message.join(''));\n    const messageFreq = messages.reduce((freq, msg) => {\n      freq[msg] = (freq[msg] || 0) + 1;\n      return freq;\n    }, {});\n    const messageEntropy = Object.values(messageFreq).reduce((entropy, freq) => {\n      const p = freq / messages.length;\n      return entropy - p * Math.log2(p);\n    }, 0);\n    return {\n      timestamp: Date.now(),\n      averageReward,\n      resourceConflicts,\n      cooperativeActions,\n      messageEntropy\n    };\n  };\n\n  // Animation loop\n  const animate = () => {\n    if (!isRunning) return;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n\n    // Clear canvas\n    ctx.fillStyle = '#1a1a1a';\n    ctx.fillRect(0, 0, canvas.width, canvas.height);\n\n    // Draw resources\n    resourcesRef.current.forEach(resource => {\n      ctx.fillStyle = `hsla(${resource.value}, 70%, 50%, 0.8)`;\n      ctx.beginPath();\n      ctx.arc(resource.x, resource.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n    });\n\n    // Draw agents\n    agentsRef.current.forEach(agent => {\n      // Draw agent body\n      ctx.fillStyle = `hsl(${agent.id * 137.5 % 360}, 70%, 50%)`;\n      ctx.beginPath();\n      ctx.arc(agent.x, agent.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n\n      // Draw communication range when agent is sending message\n      if (agent.message.some(bit => bit === 1)) {\n        ctx.strokeStyle = `hsla(${agent.id * 137.5 % 360}, 70%, 50%, 0.2)`;\n        ctx.beginPath();\n        ctx.arc(agent.x, agent.y, settings.communicationRange, 0, Math.PI * 2);\n        ctx.stroke();\n      }\n    });\n\n    // Update simulation\n    updateSimulation();\n    animationFrameRef.current = requestAnimationFrame(animate);\n  };\n\n  // Calculate distance between two points\n  const distance = (p1, p2) => {\n    const dx = p2.x - p1.x;\n    const dy = p2.y - p1.y;\n    return Math.sqrt(dx * dx + dy * dy);\n  };\n\n  // Setup and cleanup\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    canvas.width = 600;\n    canvas.height = 400;\n    initializeSimulation();\n    return () => {\n      if (animationFrameRef.current) {\n        cancelAnimationFrame(animationFrameRef.current);\n      }\n    };\n  }, []);\n  useEffect(() => {\n    if (isRunning) {\n      animate();\n    } else if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current);\n    }\n  }, [isRunning]);\n  const handleSettingChange = (setting, value) => {\n    setSettings(prev => ({\n      ...prev,\n      [setting]: parseFloat(value)\n    }));\n  };\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"p-4 space-y-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 342,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    className: \"space-y-2\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 343,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"h2\", {\n    className: \"text-xl font-bold\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 344,\n      columnNumber: 9\n    }\n  }, \"Multi-Agent Reinforcement Learning Simulation\"), /*#__PURE__*/React.createElement(Alert, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 345,\n      columnNumber: 9\n    }\n  }, \"This simulation demonstrates emergent cooperation and competition between agents learning to gather resources while developing communication protocols.\")), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"space-y-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 351,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"canvas\", {\n    ref: canvasRef,\n    className: \"border border-gray-300 rounded-lg\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 352,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"flex gap-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 357,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    className: \"px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600\",\n    onClick: () => setIsRunning(!isRunning),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 358,\n      columnNumber: 11\n    }\n  }, isRunning ? 'Pause' : 'Start'), /*#__PURE__*/React.createElement(\"button\", {\n    className: \"px-4 py-2 bg-gray-500 text-white rounded hover:bg-gray-600\",\n    onClick: initializeSimulation,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 364,\n      columnNumber: 11\n    }\n  }, \"Reset\")), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 372,\n      columnNumber: 9\n    }\n  }, Object.entries(settings).map(([key, value]) => /*#__PURE__*/React.createElement(\"div\", {\n    key: key,\n    className: \"space-y-1\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 374,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"label\", {\n    className: \"text-sm font-medium\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 375,\n      columnNumber: 15\n    }\n  }, key.split(/(?=[A-Z])/).join(' ')), /*#__PURE__*/React.createElement(\"input\", {\n    type: \"range\",\n    min: key.includes('Rate') ? 0 : 1,\n    max: key === 'numAgents' ? 50 : key === 'numResources' ? 100 : key === 'communicationRange' ? 100 : key.includes('Rate') ? 1 : 10,\n    step: key.includes('Rate') ? 0.01 : 1,\n    value: value,\n    onChange: e => handleSettingChange(key, e.target.value),\n    className: \"w-full\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 378,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(\"span\", {\n    className: \"text-sm\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 390,\n      columnNumber: 15\n    }\n  }, value)))), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"space-y-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 396,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"h3\", {\n    className: \"text-lg font-semibold\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 397,\n      columnNumber: 11\n    }\n  }, \"Learning Progress\"), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"h-64\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 398,\n      columnNumber: 11\n    }\n  }, /*#__PURE__*/React.createElement(LineChart, {\n    width: 600,\n    height: 200,\n    data: metrics,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 399,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(CartesianGrid, {\n    strokeDasharray: \"3 3\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 400,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(XAxis, {\n    dataKey: \"timestamp\",\n    type: \"number\",\n    domain: ['auto', 'auto'],\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 401,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(YAxis, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 402,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Tooltip, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 403,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Legend, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 404,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"averageReward\",\n    stroke: \"#8884d8\",\n    name: \"Average Reward\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 405,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"resourceConflicts\",\n    stroke: \"#82ca9d\",\n    name: \"Resource Conflicts\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 406,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"cooperativeActions\",\n    stroke: \"#ffc658\",\n    name: \"Cooperative Actions\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 407,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"messageEntropy\",\n    stroke: \"#ff8042\",\n    name: \"Message Entropy\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 408,\n      columnNumber: 15\n    }\n  }))))));\n};\nexport default MARLSimulation;","map":{"version":3,"names":["React","useState","useEffect","useRef","Alert","LineChart","Line","XAxis","YAxis","CartesianGrid","Tooltip","Legend","AgentNetwork","constructor","inputSize","hiddenSize","outputSize","weights1","Array","fill","map","Math","random","weights2","forward","inputs","hidden","_","i","reduce","sum","w","j","x","max","outputs","row","h","exp","Agent","y","id","energy","message","network","reward","memory","act","state","dx","dy","action","slice","learn","experience","push","Resource","value","MARLSimulation","canvasRef","agentsRef","resourcesRef","animationFrameRef","isRunning","setIsRunning","metrics","setMetrics","timestamp","Date","now","averageReward","resourceConflicts","cooperativeActions","messageEntropy","settings","setSettings","numAgents","numResources","learningRate","explorationRate","communicationRange","resourceRegenerationRate","initializeSimulation","canvas","current","newAgents","width","height","newResources","getAgentState","agent","nearbyResources","filter","r","distance","nearbyAgents","a","receivedMessage","length","updateSimulation","updatedAgents","newX","newY","resource","competingAgents","totalAgents","cooperativeAgents","some","bit","min","nextState","newMetrics","calculateMetrics","prev","agents","count","messages","join","messageFreq","freq","msg","Object","values","entropy","p","log2","animate","ctx","getContext","fillStyle","fillRect","forEach","beginPath","arc","PI","strokeStyle","stroke","requestAnimationFrame","p1","p2","sqrt","cancelAnimationFrame","handleSettingChange","setting","parseFloat","createElement","className","__self","__source","fileName","_jsxFileName","lineNumber","columnNumber","ref","onClick","entries","key","split","type","includes","step","onChange","e","target","data","strokeDasharray","dataKey","domain","name"],"sources":["/Users/yuvvan_talreja/Desktop/Coding/agentic-research/src/App.js"],"sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport { Alert } from '@/components/ui/alert';\nimport { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend } from 'recharts';\n\n// Neural Network for each agent\nclass AgentNetwork {\n  constructor(inputSize, hiddenSize, outputSize) {\n    this.weights1 = new Array(inputSize).fill(0).map(() => \n      new Array(hiddenSize).fill(0).map(() => Math.random() * 2 - 1)\n    );\n    this.weights2 = new Array(hiddenSize).fill(0).map(() => \n      new Array(outputSize).fill(0).map(() => Math.random() * 2 - 1)\n    );\n  }\n\n  forward(inputs) {\n    // Simple feedforward network with ReLU activation\n    const hidden = inputs.map((_, i) => \n      this.weights1[i].reduce((sum, w, j) => sum + w * inputs[j], 0)\n    ).map(x => Math.max(0, x));\n\n    const outputs = this.weights2.map(row =>\n      hidden.reduce((sum, h, j) => sum + h * row[j], 0)\n    ).map(x => 1 / (1 + Math.exp(-x))); // Sigmoid for output\n\n    return outputs;\n  }\n}\n\nclass Agent {\n  constructor(x, y, id) {\n    this.x = x;\n    this.y = y;\n    this.id = id;\n    this.energy = 100;\n    this.message = new Array(4).fill(0); // 4-bit message vector\n    this.network = new AgentNetwork(12, 8, 6); // Input: position(2), energy(1), resources nearby(5), message received(4)\n                                              // Output: movement(2), action(2), message(2)\n    this.reward = 0;\n    this.memory = [];\n  }\n\n  act(state) {\n    const outputs = this.network.forward(state);\n    return {\n      dx: outputs[0] * 2 - 1, // Movement in x (-1 to 1)\n      dy: outputs[1] * 2 - 1, // Movement in y (-1 to 1)\n      action: outputs.slice(2, 4), // Action probabilities\n      message: outputs.slice(4, 6).map(x => x > 0.5 ? 1 : 0) // Binary message bits\n    };\n  }\n\n  learn(experience) {\n    this.memory.push(experience);\n    // Implement Q-learning or policy gradient here\n    // For now, we'll use a simple reward accumulation\n    this.reward += experience.reward;\n  }\n}\n\nclass Resource {\n  constructor(x, y, value) {\n    this.x = x;\n    this.y = y;\n    this.value = value;\n  }\n}\n\nconst MARLSimulation = () => {\n  const canvasRef = useRef(null);\n  const agentsRef = useRef([]);\n  const resourcesRef = useRef([]);\n  const animationFrameRef = useRef(null);\n  \n  const [isRunning, setIsRunning] = useState(false);\n  const [metrics, setMetrics] = useState([{\n    timestamp: Date.now(),\n    averageReward: 0,\n    resourceConflicts: 0,\n    cooperativeActions: 0,\n    messageEntropy: 0\n  }]);\n\n  const [settings, setSettings] = useState({\n    numAgents: 10,\n    numResources: 20,\n    learningRate: 0.01,\n    explorationRate: 0.1,\n    communicationRange: 50,\n    resourceRegenerationRate: 0.01\n  });\n\n  // Initialize simulation\n  const initializeSimulation = () => {\n    const canvas = canvasRef.current;\n    \n    // Initialize agents\n    const newAgents = [];\n    for (let i = 0; i < settings.numAgents; i++) {\n      newAgents.push(new Agent(\n        Math.random() * canvas.width,\n        Math.random() * canvas.height,\n        i\n      ));\n    }\n    agentsRef.current = newAgents;\n\n    // Initialize resources\n    const newResources = [];\n    for (let i = 0; i < settings.numResources; i++) {\n      newResources.push(new Resource(\n        Math.random() * canvas.width,\n        Math.random() * canvas.height,\n        Math.random() * 50 + 50\n      ));\n    }\n    resourcesRef.current = newResources;\n  };\n\n  // Calculate state for an agent\n  const getAgentState = (agent) => {\n    const nearbyResources = resourcesRef.current\n      .filter(r => distance(agent, r) < settings.communicationRange)\n      .slice(0, 5)\n      .map(r => distance(agent, r) / settings.communicationRange);\n    \n    const nearbyAgents = agentsRef.current\n      .filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n    \n    const receivedMessage = nearbyAgents.length > 0 \n      ? nearbyAgents[0].message \n      : [0, 0, 0, 0];\n\n    return [\n      agent.x / canvasRef.current.width,\n      agent.y / canvasRef.current.height,\n      agent.energy / 100,\n      ...nearbyResources,\n      ...new Array(5 - nearbyResources.length).fill(1),\n      ...receivedMessage\n    ];\n  };\n\n  // Update simulation state\n  const updateSimulation = () => {\n    const canvas = canvasRef.current;\n    const updatedAgents = agentsRef.current.map(agent => {\n      const state = getAgentState(agent);\n      const action = agent.act(state);\n\n      // Update position\n      const newX = (agent.x + action.dx * 5 + canvas.width) % canvas.width;\n      const newY = (agent.y + action.dy * 5 + canvas.height) % canvas.height;\n\n      // Check for resources\n      const nearbyResources = resourcesRef.current.filter(r => distance({x: newX, y: newY}, r) < 10);\n      let reward = 0;\n\n      if (nearbyResources.length > 0) {\n        const resource = nearbyResources[0];\n        const competingAgents = agentsRef.current.filter(\n          a => a !== agent && distance({x: newX, y: newY}, resource) < 10\n        );\n\n        if (competingAgents.length > 0) {\n          // Resource competition scenario\n          const totalAgents = competingAgents.length + 1;\n          reward = resource.value / totalAgents;\n          \n          // Encourage cooperation through communication\n          const cooperativeAgents = competingAgents.filter(\n            a => a.message.some(bit => bit === 1)\n          );\n          \n          if (cooperativeAgents.length > 0) {\n            reward *= 1.5; // Bonus for cooperative behavior\n          }\n        } else {\n          reward = resource.value;\n        }\n\n        resource.value *= (1 - 0.5); // Deplete resource\n        if (resource.value < 10) {\n          resourcesRef.current = resourcesRef.current.filter(r => r !== resource);\n        }\n      }\n\n      // Update agent\n      agent.x = newX;\n      agent.y = newY;\n      agent.energy = Math.min(100, agent.energy + reward);\n      agent.message = action.message;\n      \n      // Learn from experience\n      agent.learn({\n        state,\n        action,\n        reward,\n        nextState: getAgentState(agent)\n      });\n\n      return agent;\n    });\n\n    // Regenerate resources\n    if (Math.random() < settings.resourceRegenerationRate && \n        resourcesRef.current.length < settings.numResources) {\n      resourcesRef.current.push(new Resource(\n        Math.random() * canvas.width,\n        Math.random() * canvas.height,\n        Math.random() * 50 + 50\n      ));\n    }\n\n    agentsRef.current = updatedAgents;\n    \n    // Update metrics\n    if (Date.now() % 10 === 0) {\n      const newMetrics = calculateMetrics();\n      setMetrics(prev => [...prev.slice(-50), newMetrics]);\n    }\n  };\n\n  // Calculate simulation metrics\n  const calculateMetrics = () => {\n    const agents = agentsRef.current;\n    \n    // Calculate average reward\n    const averageReward = agents.reduce((sum, agent) => sum + agent.reward, 0) / agents.length;\n    \n    // Count resource conflicts\n    const resourceConflicts = resourcesRef.current.reduce((count, resource) => {\n      const nearbyAgents = agents.filter(a => distance(a, resource) < 10);\n      return count + (nearbyAgents.length > 1 ? 1 : 0);\n    }, 0);\n    \n    // Count cooperative actions (agents sharing resources when communicating)\n    const cooperativeActions = agents.reduce((count, agent) => {\n      const nearbyAgents = agents.filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n      return count + (nearbyAgents.some(a => a.message.some(bit => bit === 1)) ? 1 : 0);\n    }, 0);\n    \n    // Calculate message entropy (measure of communication diversity)\n    const messages = agents.map(a => a.message.join(''));\n    const messageFreq = messages.reduce((freq, msg) => {\n      freq[msg] = (freq[msg] || 0) + 1;\n      return freq;\n    }, {});\n    const messageEntropy = Object.values(messageFreq).reduce((entropy, freq) => {\n      const p = freq / messages.length;\n      return entropy - p * Math.log2(p);\n    }, 0);\n    \n    return {\n      timestamp: Date.now(),\n      averageReward,\n      resourceConflicts,\n      cooperativeActions,\n      messageEntropy\n    };\n  };\n\n  // Animation loop\n  const animate = () => {\n    if (!isRunning) return;\n    \n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    \n    // Clear canvas\n    ctx.fillStyle = '#1a1a1a';\n    ctx.fillRect(0, 0, canvas.width, canvas.height);\n    \n    // Draw resources\n    resourcesRef.current.forEach(resource => {\n      ctx.fillStyle = `hsla(${resource.value}, 70%, 50%, 0.8)`;\n      ctx.beginPath();\n      ctx.arc(resource.x, resource.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n    });\n    \n    // Draw agents\n    agentsRef.current.forEach(agent => {\n      // Draw agent body\n      ctx.fillStyle = `hsl(${agent.id * 137.5 % 360}, 70%, 50%)`;\n      ctx.beginPath();\n      ctx.arc(agent.x, agent.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n      \n      // Draw communication range when agent is sending message\n      if (agent.message.some(bit => bit === 1)) {\n        ctx.strokeStyle = `hsla(${agent.id * 137.5 % 360}, 70%, 50%, 0.2)`;\n        ctx.beginPath();\n        ctx.arc(agent.x, agent.y, settings.communicationRange, 0, Math.PI * 2);\n        ctx.stroke();\n      }\n    });\n    \n    // Update simulation\n    updateSimulation();\n    \n    animationFrameRef.current = requestAnimationFrame(animate);\n  };\n\n  // Calculate distance between two points\n  const distance = (p1, p2) => {\n    const dx = p2.x - p1.x;\n    const dy = p2.y - p1.y;\n    return Math.sqrt(dx * dx + dy * dy);\n  };\n\n  // Setup and cleanup\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    canvas.width = 600;\n    canvas.height = 400;\n    initializeSimulation();\n\n    return () => {\n      if (animationFrameRef.current) {\n        cancelAnimationFrame(animationFrameRef.current);\n      }\n    };\n  }, []);\n\n  useEffect(() => {\n    if (isRunning) {\n      animate();\n    } else if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current);\n    }\n  }, [isRunning]);\n\n  const handleSettingChange = (setting, value) => {\n    setSettings(prev => ({\n      ...prev,\n      [setting]: parseFloat(value)\n    }));\n  };\n\n  return (\n    <div className=\"p-4 space-y-4\">\n      <div className=\"space-y-2\">\n        <h2 className=\"text-xl font-bold\">Multi-Agent Reinforcement Learning Simulation</h2>\n        <Alert>\n          This simulation demonstrates emergent cooperation and competition between agents\n          learning to gather resources while developing communication protocols.\n        </Alert>\n      </div>\n      \n      <div className=\"space-y-4\">\n        <canvas\n          ref={canvasRef}\n          className=\"border border-gray-300 rounded-lg\"\n        />\n        \n        <div className=\"flex gap-4\">\n          <button\n            className=\"px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600\"\n            onClick={() => setIsRunning(!isRunning)}\n          >\n            {isRunning ? 'Pause' : 'Start'}\n          </button>\n          <button\n            className=\"px-4 py-2 bg-gray-500 text-white rounded hover:bg-gray-600\"\n            onClick={initializeSimulation}\n          >\n            Reset\n          </button>\n        </div>\n        \n        <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4\">\n          {Object.entries(settings).map(([key, value]) => (\n            <div key={key} className=\"space-y-1\">\n              <label className=\"text-sm font-medium\">\n                {key.split(/(?=[A-Z])/).join(' ')}\n              </label>\n              <input\n                type=\"range\"\n                min={key.includes('Rate') ? 0 : 1}\n                max={key === 'numAgents' ? 50 : \n                     key === 'numResources' ? 100 :\n                     key === 'communicationRange' ? 100 :\n                     key.includes('Rate') ? 1 : 10}\n                step={key.includes('Rate') ? 0.01 : 1}\n                value={value}\n                onChange={(e) => handleSettingChange(key, e.target.value)}\n                className=\"w-full\"\n              />\n              <span className=\"text-sm\">{value}</span>\n            </div>\n          ))}\n        </div>\n\n        {/* Metrics visualization */}\n        <div className=\"space-y-4\">\n          <h3 className=\"text-lg font-semibold\">Learning Progress</h3>\n          <div className=\"h-64\">\n            <LineChart width={600} height={200} data={metrics}>\n              <CartesianGrid strokeDasharray=\"3 3\" />\n              <XAxis dataKey=\"timestamp\" type=\"number\" domain={['auto', 'auto']} />\n              <YAxis />\n              <Tooltip />\n              <Legend />\n              <Line type=\"monotone\" dataKey=\"averageReward\" stroke=\"#8884d8\" name=\"Average Reward\" />\n              <Line type=\"monotone\" dataKey=\"resourceConflicts\" stroke=\"#82ca9d\" name=\"Resource Conflicts\" />\n              <Line type=\"monotone\" dataKey=\"cooperativeActions\" stroke=\"#ffc658\" name=\"Cooperative Actions\" />\n              <Line type=\"monotone\" dataKey=\"messageEntropy\" stroke=\"#ff8042\" name=\"Message Entropy\" />\n            </LineChart>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default MARLSimulation;"],"mappings":";AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAC1D,SAASC,KAAK,QAAQ,uBAAuB;AAC7C,SAASC,SAAS,EAAEC,IAAI,EAAEC,KAAK,EAAEC,KAAK,EAAEC,aAAa,EAAEC,OAAO,EAAEC,MAAM,QAAQ,UAAU;;AAExF;AACA,MAAMC,YAAY,CAAC;EACjBC,WAAWA,CAACC,SAAS,EAAEC,UAAU,EAAEC,UAAU,EAAE;IAC7C,IAAI,CAACC,QAAQ,GAAG,IAAIC,KAAK,CAACJ,SAAS,CAAC,CAACK,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAC/C,IAAIF,KAAK,CAACH,UAAU,CAAC,CAACI,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAAMC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAC/D,CAAC;IACD,IAAI,CAACC,QAAQ,GAAG,IAAIL,KAAK,CAACH,UAAU,CAAC,CAACI,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAChD,IAAIF,KAAK,CAACF,UAAU,CAAC,CAACG,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAAMC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAC/D,CAAC;EACH;EAEAE,OAAOA,CAACC,MAAM,EAAE;IACd;IACA,MAAMC,MAAM,GAAGD,MAAM,CAACL,GAAG,CAAC,CAACO,CAAC,EAAEC,CAAC,KAC7B,IAAI,CAACX,QAAQ,CAACW,CAAC,CAAC,CAACC,MAAM,CAAC,CAACC,GAAG,EAAEC,CAAC,EAAEC,CAAC,KAAKF,GAAG,GAAGC,CAAC,GAAGN,MAAM,CAACO,CAAC,CAAC,EAAE,CAAC,CAC/D,CAAC,CAACZ,GAAG,CAACa,CAAC,IAAIZ,IAAI,CAACa,GAAG,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC;IAE1B,MAAME,OAAO,GAAG,IAAI,CAACZ,QAAQ,CAACH,GAAG,CAACgB,GAAG,IACnCV,MAAM,CAACG,MAAM,CAAC,CAACC,GAAG,EAAEO,CAAC,EAAEL,CAAC,KAAKF,GAAG,GAAGO,CAAC,GAAGD,GAAG,CAACJ,CAAC,CAAC,EAAE,CAAC,CAClD,CAAC,CAACZ,GAAG,CAACa,CAAC,IAAI,CAAC,IAAI,CAAC,GAAGZ,IAAI,CAACiB,GAAG,CAAC,CAACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;;IAEpC,OAAOE,OAAO;EAChB;AACF;AAEA,MAAMI,KAAK,CAAC;EACV1B,WAAWA,CAACoB,CAAC,EAAEO,CAAC,EAAEC,EAAE,EAAE;IACpB,IAAI,CAACR,CAAC,GAAGA,CAAC;IACV,IAAI,CAACO,CAAC,GAAGA,CAAC;IACV,IAAI,CAACC,EAAE,GAAGA,EAAE;IACZ,IAAI,CAACC,MAAM,GAAG,GAAG;IACjB,IAAI,CAACC,OAAO,GAAG,IAAIzB,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;IACrC,IAAI,CAACyB,OAAO,GAAG,IAAIhC,YAAY,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;IACD;IAC1C,IAAI,CAACiC,MAAM,GAAG,CAAC;IACf,IAAI,CAACC,MAAM,GAAG,EAAE;EAClB;EAEAC,GAAGA,CAACC,KAAK,EAAE;IACT,MAAMb,OAAO,GAAG,IAAI,CAACS,OAAO,CAACpB,OAAO,CAACwB,KAAK,CAAC;IAC3C,OAAO;MACLC,EAAE,EAAEd,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;MAAE;MACxBe,EAAE,EAAEf,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;MAAE;MACxBgB,MAAM,EAAEhB,OAAO,CAACiB,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;MAAE;MAC7BT,OAAO,EAAER,OAAO,CAACiB,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAChC,GAAG,CAACa,CAAC,IAAIA,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC;IACzD,CAAC;EACH;EAEAoB,KAAKA,CAACC,UAAU,EAAE;IAChB,IAAI,CAACR,MAAM,CAACS,IAAI,CAACD,UAAU,CAAC;IAC5B;IACA;IACA,IAAI,CAACT,MAAM,IAAIS,UAAU,CAACT,MAAM;EAClC;AACF;AAEA,MAAMW,QAAQ,CAAC;EACb3C,WAAWA,CAACoB,CAAC,EAAEO,CAAC,EAAEiB,KAAK,EAAE;IACvB,IAAI,CAACxB,CAAC,GAAGA,CAAC;IACV,IAAI,CAACO,CAAC,GAAGA,CAAC;IACV,IAAI,CAACiB,KAAK,GAAGA,KAAK;EACpB;AACF;AAEA,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAC3B,MAAMC,SAAS,GAAGxD,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMyD,SAAS,GAAGzD,MAAM,CAAC,EAAE,CAAC;EAC5B,MAAM0D,YAAY,GAAG1D,MAAM,CAAC,EAAE,CAAC;EAC/B,MAAM2D,iBAAiB,GAAG3D,MAAM,CAAC,IAAI,CAAC;EAEtC,MAAM,CAAC4D,SAAS,EAAEC,YAAY,CAAC,GAAG/D,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACgE,OAAO,EAAEC,UAAU,CAAC,GAAGjE,QAAQ,CAAC,CAAC;IACtCkE,SAAS,EAAEC,IAAI,CAACC,GAAG,CAAC,CAAC;IACrBC,aAAa,EAAE,CAAC;IAChBC,iBAAiB,EAAE,CAAC;IACpBC,kBAAkB,EAAE,CAAC;IACrBC,cAAc,EAAE;EAClB,CAAC,CAAC,CAAC;EAEH,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAG1E,QAAQ,CAAC;IACvC2E,SAAS,EAAE,EAAE;IACbC,YAAY,EAAE,EAAE;IAChBC,YAAY,EAAE,IAAI;IAClBC,eAAe,EAAE,GAAG;IACpBC,kBAAkB,EAAE,EAAE;IACtBC,wBAAwB,EAAE;EAC5B,CAAC,CAAC;;EAEF;EACA,MAAMC,oBAAoB,GAAGA,CAAA,KAAM;IACjC,MAAMC,MAAM,GAAGxB,SAAS,CAACyB,OAAO;;IAEhC;IACA,MAAMC,SAAS,GAAG,EAAE;IACpB,KAAK,IAAIzD,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8C,QAAQ,CAACE,SAAS,EAAEhD,CAAC,EAAE,EAAE;MAC3CyD,SAAS,CAAC9B,IAAI,CAAC,IAAIhB,KAAK,CACtBlB,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG6D,MAAM,CAACG,KAAK,EAC5BjE,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG6D,MAAM,CAACI,MAAM,EAC7B3D,CACF,CAAC,CAAC;IACJ;IACAgC,SAAS,CAACwB,OAAO,GAAGC,SAAS;;IAE7B;IACA,MAAMG,YAAY,GAAG,EAAE;IACvB,KAAK,IAAI5D,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG8C,QAAQ,CAACG,YAAY,EAAEjD,CAAC,EAAE,EAAE;MAC9C4D,YAAY,CAACjC,IAAI,CAAC,IAAIC,QAAQ,CAC5BnC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG6D,MAAM,CAACG,KAAK,EAC5BjE,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG6D,MAAM,CAACI,MAAM,EAC7BlE,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EACvB,CAAC,CAAC;IACJ;IACAuC,YAAY,CAACuB,OAAO,GAAGI,YAAY;EACrC,CAAC;;EAED;EACA,MAAMC,aAAa,GAAIC,KAAK,IAAK;IAC/B,MAAMC,eAAe,GAAG9B,YAAY,CAACuB,OAAO,CACzCQ,MAAM,CAACC,CAAC,IAAIC,QAAQ,CAACJ,KAAK,EAAEG,CAAC,CAAC,GAAGnB,QAAQ,CAACM,kBAAkB,CAAC,CAC7D5B,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CACXhC,GAAG,CAACyE,CAAC,IAAIC,QAAQ,CAACJ,KAAK,EAAEG,CAAC,CAAC,GAAGnB,QAAQ,CAACM,kBAAkB,CAAC;IAE7D,MAAMe,YAAY,GAAGnC,SAAS,CAACwB,OAAO,CACnCQ,MAAM,CAACI,CAAC,IAAIA,CAAC,KAAKN,KAAK,IAAII,QAAQ,CAACJ,KAAK,EAAEM,CAAC,CAAC,GAAGtB,QAAQ,CAACM,kBAAkB,CAAC;IAE/E,MAAMiB,eAAe,GAAGF,YAAY,CAACG,MAAM,GAAG,CAAC,GAC3CH,YAAY,CAAC,CAAC,CAAC,CAACpD,OAAO,GACvB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;IAEhB,OAAO,CACL+C,KAAK,CAACzD,CAAC,GAAG0B,SAAS,CAACyB,OAAO,CAACE,KAAK,EACjCI,KAAK,CAAClD,CAAC,GAAGmB,SAAS,CAACyB,OAAO,CAACG,MAAM,EAClCG,KAAK,CAAChD,MAAM,GAAG,GAAG,EAClB,GAAGiD,eAAe,EAClB,GAAG,IAAIzE,KAAK,CAAC,CAAC,GAAGyE,eAAe,CAACO,MAAM,CAAC,CAAC/E,IAAI,CAAC,CAAC,CAAC,EAChD,GAAG8E,eAAe,CACnB;EACH,CAAC;;EAED;EACA,MAAME,gBAAgB,GAAGA,CAAA,KAAM;IAC7B,MAAMhB,MAAM,GAAGxB,SAAS,CAACyB,OAAO;IAChC,MAAMgB,aAAa,GAAGxC,SAAS,CAACwB,OAAO,CAAChE,GAAG,CAACsE,KAAK,IAAI;MACnD,MAAM1C,KAAK,GAAGyC,aAAa,CAACC,KAAK,CAAC;MAClC,MAAMvC,MAAM,GAAGuC,KAAK,CAAC3C,GAAG,CAACC,KAAK,CAAC;;MAE/B;MACA,MAAMqD,IAAI,GAAG,CAACX,KAAK,CAACzD,CAAC,GAAGkB,MAAM,CAACF,EAAE,GAAG,CAAC,GAAGkC,MAAM,CAACG,KAAK,IAAIH,MAAM,CAACG,KAAK;MACpE,MAAMgB,IAAI,GAAG,CAACZ,KAAK,CAAClD,CAAC,GAAGW,MAAM,CAACD,EAAE,GAAG,CAAC,GAAGiC,MAAM,CAACI,MAAM,IAAIJ,MAAM,CAACI,MAAM;;MAEtE;MACA,MAAMI,eAAe,GAAG9B,YAAY,CAACuB,OAAO,CAACQ,MAAM,CAACC,CAAC,IAAIC,QAAQ,CAAC;QAAC7D,CAAC,EAAEoE,IAAI;QAAE7D,CAAC,EAAE8D;MAAI,CAAC,EAAET,CAAC,CAAC,GAAG,EAAE,CAAC;MAC9F,IAAIhD,MAAM,GAAG,CAAC;MAEd,IAAI8C,eAAe,CAACO,MAAM,GAAG,CAAC,EAAE;QAC9B,MAAMK,QAAQ,GAAGZ,eAAe,CAAC,CAAC,CAAC;QACnC,MAAMa,eAAe,GAAG5C,SAAS,CAACwB,OAAO,CAACQ,MAAM,CAC9CI,CAAC,IAAIA,CAAC,KAAKN,KAAK,IAAII,QAAQ,CAAC;UAAC7D,CAAC,EAAEoE,IAAI;UAAE7D,CAAC,EAAE8D;QAAI,CAAC,EAAEC,QAAQ,CAAC,GAAG,EAC/D,CAAC;QAED,IAAIC,eAAe,CAACN,MAAM,GAAG,CAAC,EAAE;UAC9B;UACA,MAAMO,WAAW,GAAGD,eAAe,CAACN,MAAM,GAAG,CAAC;UAC9CrD,MAAM,GAAG0D,QAAQ,CAAC9C,KAAK,GAAGgD,WAAW;;UAErC;UACA,MAAMC,iBAAiB,GAAGF,eAAe,CAACZ,MAAM,CAC9CI,CAAC,IAAIA,CAAC,CAACrD,OAAO,CAACgE,IAAI,CAACC,GAAG,IAAIA,GAAG,KAAK,CAAC,CACtC,CAAC;UAED,IAAIF,iBAAiB,CAACR,MAAM,GAAG,CAAC,EAAE;YAChCrD,MAAM,IAAI,GAAG,CAAC,CAAC;UACjB;QACF,CAAC,MAAM;UACLA,MAAM,GAAG0D,QAAQ,CAAC9C,KAAK;QACzB;QAEA8C,QAAQ,CAAC9C,KAAK,IAAK,CAAC,GAAG,GAAI,CAAC,CAAC;QAC7B,IAAI8C,QAAQ,CAAC9C,KAAK,GAAG,EAAE,EAAE;UACvBI,YAAY,CAACuB,OAAO,GAAGvB,YAAY,CAACuB,OAAO,CAACQ,MAAM,CAACC,CAAC,IAAIA,CAAC,KAAKU,QAAQ,CAAC;QACzE;MACF;;MAEA;MACAb,KAAK,CAACzD,CAAC,GAAGoE,IAAI;MACdX,KAAK,CAAClD,CAAC,GAAG8D,IAAI;MACdZ,KAAK,CAAChD,MAAM,GAAGrB,IAAI,CAACwF,GAAG,CAAC,GAAG,EAAEnB,KAAK,CAAChD,MAAM,GAAGG,MAAM,CAAC;MACnD6C,KAAK,CAAC/C,OAAO,GAAGQ,MAAM,CAACR,OAAO;;MAE9B;MACA+C,KAAK,CAACrC,KAAK,CAAC;QACVL,KAAK;QACLG,MAAM;QACNN,MAAM;QACNiE,SAAS,EAAErB,aAAa,CAACC,KAAK;MAChC,CAAC,CAAC;MAEF,OAAOA,KAAK;IACd,CAAC,CAAC;;IAEF;IACA,IAAIrE,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGoD,QAAQ,CAACO,wBAAwB,IACjDpB,YAAY,CAACuB,OAAO,CAACc,MAAM,GAAGxB,QAAQ,CAACG,YAAY,EAAE;MACvDhB,YAAY,CAACuB,OAAO,CAAC7B,IAAI,CAAC,IAAIC,QAAQ,CACpCnC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG6D,MAAM,CAACG,KAAK,EAC5BjE,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG6D,MAAM,CAACI,MAAM,EAC7BlE,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EACvB,CAAC,CAAC;IACJ;IAEAsC,SAAS,CAACwB,OAAO,GAAGgB,aAAa;;IAEjC;IACA,IAAIhC,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,EAAE,KAAK,CAAC,EAAE;MACzB,MAAM0C,UAAU,GAAGC,gBAAgB,CAAC,CAAC;MACrC9C,UAAU,CAAC+C,IAAI,IAAI,CAAC,GAAGA,IAAI,CAAC7D,KAAK,CAAC,CAAC,EAAE,CAAC,EAAE2D,UAAU,CAAC,CAAC;IACtD;EACF,CAAC;;EAED;EACA,MAAMC,gBAAgB,GAAGA,CAAA,KAAM;IAC7B,MAAME,MAAM,GAAGtD,SAAS,CAACwB,OAAO;;IAEhC;IACA,MAAMd,aAAa,GAAG4C,MAAM,CAACrF,MAAM,CAAC,CAACC,GAAG,EAAE4D,KAAK,KAAK5D,GAAG,GAAG4D,KAAK,CAAC7C,MAAM,EAAE,CAAC,CAAC,GAAGqE,MAAM,CAAChB,MAAM;;IAE1F;IACA,MAAM3B,iBAAiB,GAAGV,YAAY,CAACuB,OAAO,CAACvD,MAAM,CAAC,CAACsF,KAAK,EAAEZ,QAAQ,KAAK;MACzE,MAAMR,YAAY,GAAGmB,MAAM,CAACtB,MAAM,CAACI,CAAC,IAAIF,QAAQ,CAACE,CAAC,EAAEO,QAAQ,CAAC,GAAG,EAAE,CAAC;MACnE,OAAOY,KAAK,IAAIpB,YAAY,CAACG,MAAM,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IAClD,CAAC,EAAE,CAAC,CAAC;;IAEL;IACA,MAAM1B,kBAAkB,GAAG0C,MAAM,CAACrF,MAAM,CAAC,CAACsF,KAAK,EAAEzB,KAAK,KAAK;MACzD,MAAMK,YAAY,GAAGmB,MAAM,CAACtB,MAAM,CAACI,CAAC,IAAIA,CAAC,KAAKN,KAAK,IAAII,QAAQ,CAACJ,KAAK,EAAEM,CAAC,CAAC,GAAGtB,QAAQ,CAACM,kBAAkB,CAAC;MACxG,OAAOmC,KAAK,IAAIpB,YAAY,CAACY,IAAI,CAACX,CAAC,IAAIA,CAAC,CAACrD,OAAO,CAACgE,IAAI,CAACC,GAAG,IAAIA,GAAG,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IACnF,CAAC,EAAE,CAAC,CAAC;;IAEL;IACA,MAAMQ,QAAQ,GAAGF,MAAM,CAAC9F,GAAG,CAAC4E,CAAC,IAAIA,CAAC,CAACrD,OAAO,CAAC0E,IAAI,CAAC,EAAE,CAAC,CAAC;IACpD,MAAMC,WAAW,GAAGF,QAAQ,CAACvF,MAAM,CAAC,CAAC0F,IAAI,EAAEC,GAAG,KAAK;MACjDD,IAAI,CAACC,GAAG,CAAC,GAAG,CAACD,IAAI,CAACC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC;MAChC,OAAOD,IAAI;IACb,CAAC,EAAE,CAAC,CAAC,CAAC;IACN,MAAM9C,cAAc,GAAGgD,MAAM,CAACC,MAAM,CAACJ,WAAW,CAAC,CAACzF,MAAM,CAAC,CAAC8F,OAAO,EAAEJ,IAAI,KAAK;MAC1E,MAAMK,CAAC,GAAGL,IAAI,GAAGH,QAAQ,CAAClB,MAAM;MAChC,OAAOyB,OAAO,GAAGC,CAAC,GAAGvG,IAAI,CAACwG,IAAI,CAACD,CAAC,CAAC;IACnC,CAAC,EAAE,CAAC,CAAC;IAEL,OAAO;MACLzD,SAAS,EAAEC,IAAI,CAACC,GAAG,CAAC,CAAC;MACrBC,aAAa;MACbC,iBAAiB;MACjBC,kBAAkB;MAClBC;IACF,CAAC;EACH,CAAC;;EAED;EACA,MAAMqD,OAAO,GAAGA,CAAA,KAAM;IACpB,IAAI,CAAC/D,SAAS,EAAE;IAEhB,MAAMoB,MAAM,GAAGxB,SAAS,CAACyB,OAAO;IAChC,MAAM2C,GAAG,GAAG5C,MAAM,CAAC6C,UAAU,CAAC,IAAI,CAAC;;IAEnC;IACAD,GAAG,CAACE,SAAS,GAAG,SAAS;IACzBF,GAAG,CAACG,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE/C,MAAM,CAACG,KAAK,EAAEH,MAAM,CAACI,MAAM,CAAC;;IAE/C;IACA1B,YAAY,CAACuB,OAAO,CAAC+C,OAAO,CAAC5B,QAAQ,IAAI;MACvCwB,GAAG,CAACE,SAAS,GAAG,QAAQ1B,QAAQ,CAAC9C,KAAK,kBAAkB;MACxDsE,GAAG,CAACK,SAAS,CAAC,CAAC;MACfL,GAAG,CAACM,GAAG,CAAC9B,QAAQ,CAACtE,CAAC,EAAEsE,QAAQ,CAAC/D,CAAC,EAAE,CAAC,EAAE,CAAC,EAAEnB,IAAI,CAACiH,EAAE,GAAG,CAAC,CAAC;MAClDP,GAAG,CAAC5G,IAAI,CAAC,CAAC;IACZ,CAAC,CAAC;;IAEF;IACAyC,SAAS,CAACwB,OAAO,CAAC+C,OAAO,CAACzC,KAAK,IAAI;MACjC;MACAqC,GAAG,CAACE,SAAS,GAAG,OAAOvC,KAAK,CAACjD,EAAE,GAAG,KAAK,GAAG,GAAG,aAAa;MAC1DsF,GAAG,CAACK,SAAS,CAAC,CAAC;MACfL,GAAG,CAACM,GAAG,CAAC3C,KAAK,CAACzD,CAAC,EAAEyD,KAAK,CAAClD,CAAC,EAAE,CAAC,EAAE,CAAC,EAAEnB,IAAI,CAACiH,EAAE,GAAG,CAAC,CAAC;MAC5CP,GAAG,CAAC5G,IAAI,CAAC,CAAC;;MAEV;MACA,IAAIuE,KAAK,CAAC/C,OAAO,CAACgE,IAAI,CAACC,GAAG,IAAIA,GAAG,KAAK,CAAC,CAAC,EAAE;QACxCmB,GAAG,CAACQ,WAAW,GAAG,QAAQ7C,KAAK,CAACjD,EAAE,GAAG,KAAK,GAAG,GAAG,kBAAkB;QAClEsF,GAAG,CAACK,SAAS,CAAC,CAAC;QACfL,GAAG,CAACM,GAAG,CAAC3C,KAAK,CAACzD,CAAC,EAAEyD,KAAK,CAAClD,CAAC,EAAEkC,QAAQ,CAACM,kBAAkB,EAAE,CAAC,EAAE3D,IAAI,CAACiH,EAAE,GAAG,CAAC,CAAC;QACtEP,GAAG,CAACS,MAAM,CAAC,CAAC;MACd;IACF,CAAC,CAAC;;IAEF;IACArC,gBAAgB,CAAC,CAAC;IAElBrC,iBAAiB,CAACsB,OAAO,GAAGqD,qBAAqB,CAACX,OAAO,CAAC;EAC5D,CAAC;;EAED;EACA,MAAMhC,QAAQ,GAAGA,CAAC4C,EAAE,EAAEC,EAAE,KAAK;IAC3B,MAAM1F,EAAE,GAAG0F,EAAE,CAAC1G,CAAC,GAAGyG,EAAE,CAACzG,CAAC;IACtB,MAAMiB,EAAE,GAAGyF,EAAE,CAACnG,CAAC,GAAGkG,EAAE,CAAClG,CAAC;IACtB,OAAOnB,IAAI,CAACuH,IAAI,CAAC3F,EAAE,GAAGA,EAAE,GAAGC,EAAE,GAAGA,EAAE,CAAC;EACrC,CAAC;;EAED;EACAhD,SAAS,CAAC,MAAM;IACd,MAAMiF,MAAM,GAAGxB,SAAS,CAACyB,OAAO;IAChCD,MAAM,CAACG,KAAK,GAAG,GAAG;IAClBH,MAAM,CAACI,MAAM,GAAG,GAAG;IACnBL,oBAAoB,CAAC,CAAC;IAEtB,OAAO,MAAM;MACX,IAAIpB,iBAAiB,CAACsB,OAAO,EAAE;QAC7ByD,oBAAoB,CAAC/E,iBAAiB,CAACsB,OAAO,CAAC;MACjD;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAENlF,SAAS,CAAC,MAAM;IACd,IAAI6D,SAAS,EAAE;MACb+D,OAAO,CAAC,CAAC;IACX,CAAC,MAAM,IAAIhE,iBAAiB,CAACsB,OAAO,EAAE;MACpCyD,oBAAoB,CAAC/E,iBAAiB,CAACsB,OAAO,CAAC;IACjD;EACF,CAAC,EAAE,CAACrB,SAAS,CAAC,CAAC;EAEf,MAAM+E,mBAAmB,GAAGA,CAACC,OAAO,EAAEtF,KAAK,KAAK;IAC9CkB,WAAW,CAACsC,IAAI,KAAK;MACnB,GAAGA,IAAI;MACP,CAAC8B,OAAO,GAAGC,UAAU,CAACvF,KAAK;IAC7B,CAAC,CAAC,CAAC;EACL,CAAC;EAED,oBACEzD,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,eAAe;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAC5BxJ,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACxBxJ,KAAA,CAAAiJ,aAAA;IAAIC,SAAS,EAAC,mBAAmB;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAC,+CAAiD,CAAC,eACpFxJ,KAAA,CAAAiJ,aAAA,CAAC7I,KAAK;IAAA+I,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAC,yJAGA,CACJ,CAAC,eAENxJ,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACxBxJ,KAAA,CAAAiJ,aAAA;IACEQ,GAAG,EAAE9F,SAAU;IACfuF,SAAS,EAAC,mCAAmC;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAC9C,CAAC,eAEFxJ,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,YAAY;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACzBxJ,KAAA,CAAAiJ,aAAA;IACEC,SAAS,EAAC,4DAA4D;IACtEQ,OAAO,EAAEA,CAAA,KAAM1F,YAAY,CAAC,CAACD,SAAS,CAAE;IAAAoF,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAEvCzF,SAAS,GAAG,OAAO,GAAG,OACjB,CAAC,eACT/D,KAAA,CAAAiJ,aAAA;IACEC,SAAS,EAAC,4DAA4D;IACtEQ,OAAO,EAAExE,oBAAqB;IAAAiE,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAC/B,OAEO,CACL,CAAC,eAENxJ,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,sDAAsD;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAClE/B,MAAM,CAACkC,OAAO,CAACjF,QAAQ,CAAC,CAACtD,GAAG,CAAC,CAAC,CAACwI,GAAG,EAAEnG,KAAK,CAAC,kBACzCzD,KAAA,CAAAiJ,aAAA;IAAKW,GAAG,EAAEA,GAAI;IAACV,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAClCxJ,KAAA,CAAAiJ,aAAA;IAAOC,SAAS,EAAC,qBAAqB;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GACnCI,GAAG,CAACC,KAAK,CAAC,WAAW,CAAC,CAACxC,IAAI,CAAC,GAAG,CAC3B,CAAC,eACRrH,KAAA,CAAAiJ,aAAA;IACEa,IAAI,EAAC,OAAO;IACZjD,GAAG,EAAE+C,GAAG,CAACG,QAAQ,CAAC,MAAM,CAAC,GAAG,CAAC,GAAG,CAAE;IAClC7H,GAAG,EAAE0H,GAAG,KAAK,WAAW,GAAG,EAAE,GACxBA,GAAG,KAAK,cAAc,GAAG,GAAG,GAC5BA,GAAG,KAAK,oBAAoB,GAAG,GAAG,GAClCA,GAAG,CAACG,QAAQ,CAAC,MAAM,CAAC,GAAG,CAAC,GAAG,EAAG;IACnCC,IAAI,EAAEJ,GAAG,CAACG,QAAQ,CAAC,MAAM,CAAC,GAAG,IAAI,GAAG,CAAE;IACtCtG,KAAK,EAAEA,KAAM;IACbwG,QAAQ,EAAGC,CAAC,IAAKpB,mBAAmB,CAACc,GAAG,EAAEM,CAAC,CAACC,MAAM,CAAC1G,KAAK,CAAE;IAC1DyF,SAAS,EAAC,QAAQ;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CACnB,CAAC,eACFxJ,KAAA,CAAAiJ,aAAA;IAAMC,SAAS,EAAC,SAAS;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAE/F,KAAY,CACpC,CACN,CACE,CAAC,eAGNzD,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACxBxJ,KAAA,CAAAiJ,aAAA;IAAIC,SAAS,EAAC,uBAAuB;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAC,mBAAqB,CAAC,eAC5DxJ,KAAA,CAAAiJ,aAAA;IAAKC,SAAS,EAAC,MAAM;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACnBxJ,KAAA,CAAAiJ,aAAA,CAAC5I,SAAS;IAACiF,KAAK,EAAE,GAAI;IAACC,MAAM,EAAE,GAAI;IAAC6E,IAAI,EAAEnG,OAAQ;IAAAkF,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAChDxJ,KAAA,CAAAiJ,aAAA,CAACxI,aAAa;IAAC4J,eAAe,EAAC,KAAK;IAAAlB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACvCxJ,KAAA,CAAAiJ,aAAA,CAAC1I,KAAK;IAAC+J,OAAO,EAAC,WAAW;IAACR,IAAI,EAAC,QAAQ;IAACS,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAE;IAAApB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACrExJ,KAAA,CAAAiJ,aAAA,CAACzI,KAAK;IAAA2I,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACTxJ,KAAA,CAAAiJ,aAAA,CAACvI,OAAO;IAAAyI,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACXxJ,KAAA,CAAAiJ,aAAA,CAACtI,MAAM;IAAAwI,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACVxJ,KAAA,CAAAiJ,aAAA,CAAC3I,IAAI;IAACwJ,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,eAAe;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,gBAAgB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACvFxJ,KAAA,CAAAiJ,aAAA,CAAC3I,IAAI;IAACwJ,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,mBAAmB;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,oBAAoB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eAC/FxJ,KAAA,CAAAiJ,aAAA,CAAC3I,IAAI;IAACwJ,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,oBAAoB;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,qBAAqB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACjGxJ,KAAA,CAAAiJ,aAAA,CAAC3I,IAAI;IAACwJ,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,gBAAgB;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,iBAAiB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAC/E,CACR,CACF,CACF,CACF,CAAC;AAEV,CAAC;AAED,eAAe9F,cAAc","ignoreList":[]},"metadata":{},"sourceType":"module"}