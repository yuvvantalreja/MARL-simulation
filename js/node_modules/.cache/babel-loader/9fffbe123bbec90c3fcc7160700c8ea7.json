{"ast":null,"code":"var _jsxFileName = \"/Users/yuvvan_talreja/Desktop/Coding/agentic-research/src/App.js\";\nimport React, { useState, useEffect, useRef } from 'react';\nimport { Alert } from '@/components/ui/alert';\nimport { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend } from 'recharts';\n\n// Neural Network for each agent\nclass AgentNetwork {\n  constructor(inputSize, hiddenSize, outputSize) {\n    this.weights1 = new Array(inputSize).fill(0).map(() => new Array(hiddenSize).fill(0).map(() => Math.random() * 2 - 1));\n    this.weights2 = new Array(hiddenSize).fill(0).map(() => new Array(outputSize).fill(0).map(() => Math.random() * 2 - 1));\n  }\n  forward(inputs) {\n    // Simple feedforward network with ReLU activation\n    const hidden = inputs.map((_, i) => this.weights1[i].reduce((sum, w, j) => sum + w * inputs[j], 0)).map(x => Math.max(0, x));\n    const outputs = this.weights2.map(row => hidden.reduce((sum, h, j) => sum + h * row[j], 0)).map(x => 1 / (1 + Math.exp(-x))); // Sigmoid for output\n\n    return outputs;\n  }\n}\nclass Agent {\n  constructor(x, y, id) {\n    this.x = x;\n    this.y = y;\n    this.id = id;\n    this.energy = 100;\n    this.message = new Array(4).fill(0);\n    this.network = new AgentNetwork(12, 8, 6);\n    this.reward = 0;\n    this.memory = [];\n    this.explorationRate = 0.3; // Start with high exploration\n    this.vx = 0; // Velocity components for momentum\n    this.vy = 0;\n    this.lastAction = null;\n    this.lastReward = 0;\n  }\n  act(state) {\n    // Epsilon-greedy exploration\n    if (Math.random() < this.explorationRate) {\n      return {\n        dx: Math.random() * 2 - 1,\n        dy: Math.random() * 2 - 1,\n        action: [Math.random(), Math.random()],\n        message: Array(2).fill(0).map(() => Math.random() > 0.5 ? 1 : 0)\n      };\n    }\n    const outputs = this.network.forward(state);\n\n    // Add momentum to movement for smoother trajectories\n    this.vx = (this.vx || 0) * 0.9 + (outputs[0] * 2 - 1) * 0.1;\n    this.vy = (this.vy || 0) * 0.9 + (outputs[1] * 2 - 1) * 0.1;\n    return {\n      dx: this.vx,\n      dy: this.vy,\n      action: outputs.slice(2, 4),\n      message: outputs.slice(4, 6).map(x => x > 0.5 ? 1 : 0)\n    };\n  }\n  learn(experience) {\n    const {\n      state,\n      action,\n      reward,\n      nextState\n    } = experience;\n\n    // Q-learning update\n    const learningRate = 0.1;\n    const discountFactor = 0.95;\n\n    // Calculate TD error\n    const currentQ = this.network.forward(state);\n    const nextQ = this.network.forward(nextState);\n    const maxNextQ = Math.max(...nextQ);\n    const tdError = reward + discountFactor * maxNextQ - currentQ[0];\n\n    // Update network weights using gradient descent\n    this.weights1 = this.weights1.map(row => row.map(w => w + learningRate * tdError * state[0]));\n    this.weights2 = this.weights2.map(row => row.map(w => w + learningRate * tdError * currentQ[0]));\n    this.reward += reward;\n\n    // Exploration decay\n    this.explorationRate *= 0.999;\n  }\n}\nclass Resource {\n  constructor(x, y, value) {\n    this.x = x;\n    this.y = y;\n    this.value = value;\n  }\n}\nconst MARLSimulation = () => {\n  const canvasRef = useRef(null);\n  const agentsRef = useRef([]);\n  const resourcesRef = useRef([]);\n  const animationFrameRef = useRef(null);\n  const [isRunning, setIsRunning] = useState(false);\n  const [metrics, setMetrics] = useState([{\n    timestamp: Date.now(),\n    averageReward: 0,\n    resourceConflicts: 0,\n    cooperativeActions: 0,\n    messageEntropy: 0\n  }]);\n  const [settings, setSettings] = useState({\n    numAgents: 10,\n    numResources: 20,\n    learningRate: 0.01,\n    explorationRate: 0.1,\n    communicationRange: 50,\n    resourceRegenerationRate: 0.01\n  });\n\n  // Initialize simulation\n  const initializeSimulation = () => {\n    const canvas = canvasRef.current;\n\n    // Initialize agents\n    const newAgents = [];\n    for (let i = 0; i < settings.numAgents; i++) {\n      newAgents.push(new Agent(Math.random() * canvas.width, Math.random() * canvas.height, i));\n    }\n    agentsRef.current = newAgents;\n\n    // Initialize resources\n    const newResources = [];\n    for (let i = 0; i < settings.numResources; i++) {\n      newResources.push(new Resource(Math.random() * canvas.width, Math.random() * canvas.height, Math.random() * 50 + 50));\n    }\n    resourcesRef.current = newResources;\n  };\n\n  // Calculate state for an agent\n  const getAgentState = agent => {\n    const nearbyResources = resourcesRef.current.filter(r => distance(agent, r) < settings.communicationRange).slice(0, 5).map(r => distance(agent, r) / settings.communicationRange);\n    const nearbyAgents = agentsRef.current.filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n    const receivedMessage = nearbyAgents.length > 0 ? nearbyAgents[0].message : [0, 0, 0, 0];\n    return [agent.x / canvasRef.current.width, agent.y / canvasRef.current.height, agent.energy / 100, ...nearbyResources, ...new Array(5 - nearbyResources.length).fill(1), ...receivedMessage];\n  };\n\n  // Update simulation state\n  const updateSimulation = () => {\n    const canvas = canvasRef.current;\n    const updatedAgents = agentsRef.current.map(agent => {\n      const state = getAgentState(agent);\n      const action = agent.act(state);\n\n      // Update position\n      const newX = (agent.x + action.dx * 5 + canvas.width) % canvas.width;\n      const newY = (agent.y + action.dy * 5 + canvas.height) % canvas.height;\n\n      // Check for resources\n      const nearbyResources = resourcesRef.current.filter(r => distance({\n        x: newX,\n        y: newY\n      }, r) < 10);\n      let reward = 0;\n      if (nearbyResources.length > 0) {\n        const resource = nearbyResources[0];\n        const competingAgents = agentsRef.current.filter(a => a !== agent && distance({\n          x: newX,\n          y: newY\n        }, resource) < 10);\n        if (competingAgents.length > 0) {\n          // Resource competition scenario\n          const totalAgents = competingAgents.length + 1;\n          reward = resource.value / totalAgents;\n\n          // Encourage cooperation through communication\n          const cooperativeAgents = competingAgents.filter(a => a.message.some(bit => bit === 1));\n          if (cooperativeAgents.length > 0) {\n            reward *= 1.5; // Bonus for cooperative behavior\n          }\n        } else {\n          reward = resource.value;\n        }\n        resource.value *= 1 - 0.5; // Deplete resource\n        if (resource.value < 10) {\n          resourcesRef.current = resourcesRef.current.filter(r => r !== resource);\n        }\n      }\n\n      // Update agent\n      agent.x = newX;\n      agent.y = newY;\n      agent.energy = Math.min(100, agent.energy + reward);\n      agent.message = action.message;\n\n      // Learn from experience\n      agent.learn({\n        state,\n        action,\n        reward,\n        nextState: getAgentState(agent)\n      });\n      return agent;\n    });\n\n    // Regenerate resources\n    if (Math.random() < settings.resourceRegenerationRate && resourcesRef.current.length < settings.numResources) {\n      resourcesRef.current.push(new Resource(Math.random() * canvas.width, Math.random() * canvas.height, Math.random() * 50 + 50));\n    }\n    agentsRef.current = updatedAgents;\n\n    // Update metrics\n    if (Date.now() % 10 === 0) {\n      const newMetrics = calculateMetrics();\n      setMetrics(prev => [...prev.slice(-50), newMetrics]);\n    }\n  };\n\n  // Calculate simulation metrics\n  const calculateMetrics = () => {\n    const agents = agentsRef.current;\n\n    // Calculate average reward\n    const averageReward = agents.reduce((sum, agent) => sum + agent.reward, 0) / agents.length;\n\n    // Count resource conflicts\n    const resourceConflicts = resourcesRef.current.reduce((count, resource) => {\n      const nearbyAgents = agents.filter(a => distance(a, resource) < 10);\n      return count + (nearbyAgents.length > 1 ? 1 : 0);\n    }, 0);\n\n    // Count cooperative actions (agents sharing resources when communicating)\n    const cooperativeActions = agents.reduce((count, agent) => {\n      const nearbyAgents = agents.filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n      return count + (nearbyAgents.some(a => a.message.some(bit => bit === 1)) ? 1 : 0);\n    }, 0);\n\n    // Calculate message entropy (measure of communication diversity)\n    const messages = agents.map(a => a.message.join(''));\n    const messageFreq = messages.reduce((freq, msg) => {\n      freq[msg] = (freq[msg] || 0) + 1;\n      return freq;\n    }, {});\n    const messageEntropy = Object.values(messageFreq).reduce((entropy, freq) => {\n      const p = freq / messages.length;\n      return entropy - p * Math.log2(p);\n    }, 0);\n    return {\n      timestamp: Date.now(),\n      averageReward,\n      resourceConflicts,\n      cooperativeActions,\n      messageEntropy\n    };\n  };\n\n  // Animation loop\n  const animate = () => {\n    if (!isRunning) return;\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n\n    // Clear canvas\n    ctx.fillStyle = '#1a1a1a';\n    ctx.fillRect(0, 0, canvas.width, canvas.height);\n\n    // Draw resources\n    resourcesRef.current.forEach(resource => {\n      ctx.fillStyle = `hsla(${resource.value}, 70%, 50%, 0.8)`;\n      ctx.beginPath();\n      ctx.arc(resource.x, resource.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n    });\n\n    // Draw agents\n    agentsRef.current.forEach(agent => {\n      // Draw agent body\n      ctx.fillStyle = `hsl(${agent.id * 137.5 % 360}, 70%, 50%)`;\n      ctx.beginPath();\n      ctx.arc(agent.x, agent.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n\n      // Draw communication range when agent is sending message\n      if (agent.message.some(bit => bit === 1)) {\n        ctx.strokeStyle = `hsla(${agent.id * 137.5 % 360}, 70%, 50%, 0.2)`;\n        ctx.beginPath();\n        ctx.arc(agent.x, agent.y, settings.communicationRange, 0, Math.PI * 2);\n        ctx.stroke();\n      }\n    });\n\n    // Update simulation\n    updateSimulation();\n    animationFrameRef.current = requestAnimationFrame(animate);\n  };\n\n  // Calculate distance between two points\n  const distance = (p1, p2) => {\n    const dx = p2.x - p1.x;\n    const dy = p2.y - p1.y;\n    return Math.sqrt(dx * dx + dy * dy);\n  };\n\n  // Setup and cleanup\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    canvas.width = 600;\n    canvas.height = 400;\n    initializeSimulation();\n    return () => {\n      if (animationFrameRef.current) {\n        cancelAnimationFrame(animationFrameRef.current);\n      }\n    };\n  }, []);\n  useEffect(() => {\n    if (isRunning) {\n      animate();\n    } else if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current);\n    }\n  }, [isRunning]);\n  const handleSettingChange = (setting, value) => {\n    setSettings(prev => ({\n      ...prev,\n      [setting]: parseFloat(value)\n    }));\n  };\n  return /*#__PURE__*/React.createElement(\"div\", {\n    className: \"p-4 space-y-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 381,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"div\", {\n    className: \"space-y-2\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 382,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"h2\", {\n    className: \"text-xl font-bold\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 383,\n      columnNumber: 9\n    }\n  }, \"Multi-Agent Reinforcement Learning Simulation\"), /*#__PURE__*/React.createElement(Alert, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 384,\n      columnNumber: 9\n    }\n  }, \"This simulation demonstrates emergent cooperation and competition between agents learning to gather resources while developing communication protocols.\")), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"space-y-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 390,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(\"canvas\", {\n    ref: canvasRef,\n    className: \"border border-gray-300 rounded-lg\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 391,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"flex gap-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 396,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    className: \"px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600\",\n    onClick: () => setIsRunning(!isRunning),\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 397,\n      columnNumber: 11\n    }\n  }, isRunning ? 'Pause' : 'Start'), /*#__PURE__*/React.createElement(\"button\", {\n    className: \"px-4 py-2 bg-gray-500 text-white rounded hover:bg-gray-600\",\n    onClick: initializeSimulation,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 403,\n      columnNumber: 11\n    }\n  }, \"Reset\")), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 411,\n      columnNumber: 9\n    }\n  }, Object.entries(settings).map(([key, value]) => /*#__PURE__*/React.createElement(\"div\", {\n    key: key,\n    className: \"space-y-1\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 413,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(\"label\", {\n    className: \"text-sm font-medium\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 414,\n      columnNumber: 15\n    }\n  }, key.split(/(?=[A-Z])/).join(' ')), /*#__PURE__*/React.createElement(\"input\", {\n    type: \"range\",\n    min: key.includes('Rate') ? 0 : 1,\n    max: key === 'numAgents' ? 50 : key === 'numResources' ? 100 : key === 'communicationRange' ? 100 : key.includes('Rate') ? 1 : 10,\n    step: key.includes('Rate') ? 0.01 : 1,\n    value: value,\n    onChange: e => handleSettingChange(key, e.target.value),\n    className: \"w-full\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 417,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(\"span\", {\n    className: \"text-sm\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 429,\n      columnNumber: 15\n    }\n  }, value)))), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"space-y-4\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 435,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(\"h3\", {\n    className: \"text-lg font-semibold\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 436,\n      columnNumber: 11\n    }\n  }, \"Learning Progress\"), /*#__PURE__*/React.createElement(\"div\", {\n    className: \"h-64\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 437,\n      columnNumber: 11\n    }\n  }, /*#__PURE__*/React.createElement(LineChart, {\n    width: 600,\n    height: 200,\n    data: metrics,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 438,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(CartesianGrid, {\n    strokeDasharray: \"3 3\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 439,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(XAxis, {\n    dataKey: \"timestamp\",\n    type: \"number\",\n    domain: ['auto', 'auto'],\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 440,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(YAxis, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 441,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Tooltip, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 442,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Legend, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 443,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"averageReward\",\n    stroke: \"#8884d8\",\n    name: \"Average Reward\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 444,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"resourceConflicts\",\n    stroke: \"#82ca9d\",\n    name: \"Resource Conflicts\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 445,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"cooperativeActions\",\n    stroke: \"#ffc658\",\n    name: \"Cooperative Actions\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 446,\n      columnNumber: 15\n    }\n  }), /*#__PURE__*/React.createElement(Line, {\n    type: \"monotone\",\n    dataKey: \"messageEntropy\",\n    stroke: \"#ff8042\",\n    name: \"Message Entropy\",\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 447,\n      columnNumber: 15\n    }\n  }))))));\n};\nexport default MARLSimulation;","map":{"version":3,"names":["React","useState","useEffect","useRef","Alert","LineChart","Line","XAxis","YAxis","CartesianGrid","Tooltip","Legend","AgentNetwork","constructor","inputSize","hiddenSize","outputSize","weights1","Array","fill","map","Math","random","weights2","forward","inputs","hidden","_","i","reduce","sum","w","j","x","max","outputs","row","h","exp","Agent","y","id","energy","message","network","reward","memory","explorationRate","vx","vy","lastAction","lastReward","act","state","dx","dy","action","slice","learn","experience","nextState","learningRate","discountFactor","currentQ","nextQ","maxNextQ","tdError","Resource","value","MARLSimulation","canvasRef","agentsRef","resourcesRef","animationFrameRef","isRunning","setIsRunning","metrics","setMetrics","timestamp","Date","now","averageReward","resourceConflicts","cooperativeActions","messageEntropy","settings","setSettings","numAgents","numResources","communicationRange","resourceRegenerationRate","initializeSimulation","canvas","current","newAgents","push","width","height","newResources","getAgentState","agent","nearbyResources","filter","r","distance","nearbyAgents","a","receivedMessage","length","updateSimulation","updatedAgents","newX","newY","resource","competingAgents","totalAgents","cooperativeAgents","some","bit","min","newMetrics","calculateMetrics","prev","agents","count","messages","join","messageFreq","freq","msg","Object","values","entropy","p","log2","animate","ctx","getContext","fillStyle","fillRect","forEach","beginPath","arc","PI","strokeStyle","stroke","requestAnimationFrame","p1","p2","sqrt","cancelAnimationFrame","handleSettingChange","setting","parseFloat","createElement","className","__self","__source","fileName","_jsxFileName","lineNumber","columnNumber","ref","onClick","entries","key","split","type","includes","step","onChange","e","target","data","strokeDasharray","dataKey","domain","name"],"sources":["/Users/yuvvan_talreja/Desktop/Coding/agentic-research/src/App.js"],"sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport { Alert } from '@/components/ui/alert';\nimport { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend } from 'recharts';\n\n// Neural Network for each agent\nclass AgentNetwork {\n  constructor(inputSize, hiddenSize, outputSize) {\n    this.weights1 = new Array(inputSize).fill(0).map(() => \n      new Array(hiddenSize).fill(0).map(() => Math.random() * 2 - 1)\n    );\n    this.weights2 = new Array(hiddenSize).fill(0).map(() => \n      new Array(outputSize).fill(0).map(() => Math.random() * 2 - 1)\n    );\n  }\n\n  forward(inputs) {\n    // Simple feedforward network with ReLU activation\n    const hidden = inputs.map((_, i) => \n      this.weights1[i].reduce((sum, w, j) => sum + w * inputs[j], 0)\n    ).map(x => Math.max(0, x));\n\n    const outputs = this.weights2.map(row =>\n      hidden.reduce((sum, h, j) => sum + h * row[j], 0)\n    ).map(x => 1 / (1 + Math.exp(-x))); // Sigmoid for output\n\n    return outputs;\n  }\n}\n\nclass Agent {\n  constructor(x, y, id) {\n    this.x = x;\n    this.y = y;\n    this.id = id;\n    this.energy = 100;\n    this.message = new Array(4).fill(0);\n    this.network = new AgentNetwork(12, 8, 6);\n    this.reward = 0;\n    this.memory = [];\n    this.explorationRate = 0.3; // Start with high exploration\n    this.vx = 0; // Velocity components for momentum\n    this.vy = 0;\n    this.lastAction = null;\n    this.lastReward = 0;\n  }\n\n  act(state) {\n    // Epsilon-greedy exploration\n    if (Math.random() < this.explorationRate) {\n      return {\n        dx: Math.random() * 2 - 1,\n        dy: Math.random() * 2 - 1,\n        action: [Math.random(), Math.random()],\n        message: Array(2).fill(0).map(() => Math.random() > 0.5 ? 1 : 0)\n      };\n    }\n    \n    const outputs = this.network.forward(state);\n    \n    // Add momentum to movement for smoother trajectories\n    this.vx = (this.vx || 0) * 0.9 + (outputs[0] * 2 - 1) * 0.1;\n    this.vy = (this.vy || 0) * 0.9 + (outputs[1] * 2 - 1) * 0.1;\n    \n    return {\n      dx: this.vx,\n      dy: this.vy,\n      action: outputs.slice(2, 4),\n      message: outputs.slice(4, 6).map(x => x > 0.5 ? 1 : 0)\n    };\n  }\n\n  learn(experience) {\n    const { state, action, reward, nextState } = experience;\n    \n    // Q-learning update\n    const learningRate = 0.1;\n    const discountFactor = 0.95;\n    \n    // Calculate TD error\n    const currentQ = this.network.forward(state);\n    const nextQ = this.network.forward(nextState);\n    const maxNextQ = Math.max(...nextQ);\n    const tdError = reward + discountFactor * maxNextQ - currentQ[0];\n    \n    // Update network weights using gradient descent\n    this.weights1 = this.weights1.map(row => \n      row.map(w => w + learningRate * tdError * state[0])\n    );\n    this.weights2 = this.weights2.map(row =>\n      row.map(w => w + learningRate * tdError * currentQ[0])\n    );\n    \n    this.reward += reward;\n    \n    // Exploration decay\n    this.explorationRate *= 0.999;\n  }\n}\n\nclass Resource {\n  constructor(x, y, value) {\n    this.x = x;\n    this.y = y;\n    this.value = value;\n  }\n}\n\nconst MARLSimulation = () => {\n  const canvasRef = useRef(null);\n  const agentsRef = useRef([]);\n  const resourcesRef = useRef([]);\n  const animationFrameRef = useRef(null);\n  \n  const [isRunning, setIsRunning] = useState(false);\n  const [metrics, setMetrics] = useState([{\n    timestamp: Date.now(),\n    averageReward: 0,\n    resourceConflicts: 0,\n    cooperativeActions: 0,\n    messageEntropy: 0\n  }]);\n\n  const [settings, setSettings] = useState({\n    numAgents: 10,\n    numResources: 20,\n    learningRate: 0.01,\n    explorationRate: 0.1,\n    communicationRange: 50,\n    resourceRegenerationRate: 0.01\n  });\n\n  // Initialize simulation\n  const initializeSimulation = () => {\n    const canvas = canvasRef.current;\n    \n    // Initialize agents\n    const newAgents = [];\n    for (let i = 0; i < settings.numAgents; i++) {\n      newAgents.push(new Agent(\n        Math.random() * canvas.width,\n        Math.random() * canvas.height,\n        i\n      ));\n    }\n    agentsRef.current = newAgents;\n\n    // Initialize resources\n    const newResources = [];\n    for (let i = 0; i < settings.numResources; i++) {\n      newResources.push(new Resource(\n        Math.random() * canvas.width,\n        Math.random() * canvas.height,\n        Math.random() * 50 + 50\n      ));\n    }\n    resourcesRef.current = newResources;\n  };\n\n  // Calculate state for an agent\n  const getAgentState = (agent) => {\n    const nearbyResources = resourcesRef.current\n      .filter(r => distance(agent, r) < settings.communicationRange)\n      .slice(0, 5)\n      .map(r => distance(agent, r) / settings.communicationRange);\n    \n    const nearbyAgents = agentsRef.current\n      .filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n    \n    const receivedMessage = nearbyAgents.length > 0 \n      ? nearbyAgents[0].message \n      : [0, 0, 0, 0];\n\n    return [\n      agent.x / canvasRef.current.width,\n      agent.y / canvasRef.current.height,\n      agent.energy / 100,\n      ...nearbyResources,\n      ...new Array(5 - nearbyResources.length).fill(1),\n      ...receivedMessage\n    ];\n  };\n\n  // Update simulation state\n  const updateSimulation = () => {\n    const canvas = canvasRef.current;\n    const updatedAgents = agentsRef.current.map(agent => {\n      const state = getAgentState(agent);\n      const action = agent.act(state);\n\n      // Update position\n      const newX = (agent.x + action.dx * 5 + canvas.width) % canvas.width;\n      const newY = (agent.y + action.dy * 5 + canvas.height) % canvas.height;\n\n      // Check for resources\n      const nearbyResources = resourcesRef.current.filter(r => distance({x: newX, y: newY}, r) < 10);\n      let reward = 0;\n\n      if (nearbyResources.length > 0) {\n        const resource = nearbyResources[0];\n        const competingAgents = agentsRef.current.filter(\n          a => a !== agent && distance({x: newX, y: newY}, resource) < 10\n        );\n\n        if (competingAgents.length > 0) {\n          // Resource competition scenario\n          const totalAgents = competingAgents.length + 1;\n          reward = resource.value / totalAgents;\n          \n          // Encourage cooperation through communication\n          const cooperativeAgents = competingAgents.filter(\n            a => a.message.some(bit => bit === 1)\n          );\n          \n          if (cooperativeAgents.length > 0) {\n            reward *= 1.5; // Bonus for cooperative behavior\n          }\n        } else {\n          reward = resource.value;\n        }\n\n        resource.value *= (1 - 0.5); // Deplete resource\n        if (resource.value < 10) {\n          resourcesRef.current = resourcesRef.current.filter(r => r !== resource);\n        }\n      }\n\n      // Update agent\n      agent.x = newX;\n      agent.y = newY;\n      agent.energy = Math.min(100, agent.energy + reward);\n      agent.message = action.message;\n      \n      // Learn from experience\n      agent.learn({\n        state,\n        action,\n        reward,\n        nextState: getAgentState(agent)\n      });\n\n      return agent;\n    });\n\n    // Regenerate resources\n    if (Math.random() < settings.resourceRegenerationRate && \n        resourcesRef.current.length < settings.numResources) {\n      resourcesRef.current.push(new Resource(\n        Math.random() * canvas.width,\n        Math.random() * canvas.height,\n        Math.random() * 50 + 50\n      ));\n    }\n\n    agentsRef.current = updatedAgents;\n    \n    // Update metrics\n    if (Date.now() % 10 === 0) {\n      const newMetrics = calculateMetrics();\n      setMetrics(prev => [...prev.slice(-50), newMetrics]);\n    }\n  };\n\n  // Calculate simulation metrics\n  const calculateMetrics = () => {\n    const agents = agentsRef.current;\n    \n    // Calculate average reward\n    const averageReward = agents.reduce((sum, agent) => sum + agent.reward, 0) / agents.length;\n    \n    // Count resource conflicts\n    const resourceConflicts = resourcesRef.current.reduce((count, resource) => {\n      const nearbyAgents = agents.filter(a => distance(a, resource) < 10);\n      return count + (nearbyAgents.length > 1 ? 1 : 0);\n    }, 0);\n    \n    // Count cooperative actions (agents sharing resources when communicating)\n    const cooperativeActions = agents.reduce((count, agent) => {\n      const nearbyAgents = agents.filter(a => a !== agent && distance(agent, a) < settings.communicationRange);\n      return count + (nearbyAgents.some(a => a.message.some(bit => bit === 1)) ? 1 : 0);\n    }, 0);\n    \n    // Calculate message entropy (measure of communication diversity)\n    const messages = agents.map(a => a.message.join(''));\n    const messageFreq = messages.reduce((freq, msg) => {\n      freq[msg] = (freq[msg] || 0) + 1;\n      return freq;\n    }, {});\n    const messageEntropy = Object.values(messageFreq).reduce((entropy, freq) => {\n      const p = freq / messages.length;\n      return entropy - p * Math.log2(p);\n    }, 0);\n    \n    return {\n      timestamp: Date.now(),\n      averageReward,\n      resourceConflicts,\n      cooperativeActions,\n      messageEntropy\n    };\n  };\n\n  // Animation loop\n  const animate = () => {\n    if (!isRunning) return;\n    \n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext('2d');\n    \n    // Clear canvas\n    ctx.fillStyle = '#1a1a1a';\n    ctx.fillRect(0, 0, canvas.width, canvas.height);\n    \n    // Draw resources\n    resourcesRef.current.forEach(resource => {\n      ctx.fillStyle = `hsla(${resource.value}, 70%, 50%, 0.8)`;\n      ctx.beginPath();\n      ctx.arc(resource.x, resource.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n    });\n    \n    // Draw agents\n    agentsRef.current.forEach(agent => {\n      // Draw agent body\n      ctx.fillStyle = `hsl(${agent.id * 137.5 % 360}, 70%, 50%)`;\n      ctx.beginPath();\n      ctx.arc(agent.x, agent.y, 5, 0, Math.PI * 2);\n      ctx.fill();\n      \n      // Draw communication range when agent is sending message\n      if (agent.message.some(bit => bit === 1)) {\n        ctx.strokeStyle = `hsla(${agent.id * 137.5 % 360}, 70%, 50%, 0.2)`;\n        ctx.beginPath();\n        ctx.arc(agent.x, agent.y, settings.communicationRange, 0, Math.PI * 2);\n        ctx.stroke();\n      }\n    });\n    \n    // Update simulation\n    updateSimulation();\n    \n    animationFrameRef.current = requestAnimationFrame(animate);\n  };\n\n  // Calculate distance between two points\n  const distance = (p1, p2) => {\n    const dx = p2.x - p1.x;\n    const dy = p2.y - p1.y;\n    return Math.sqrt(dx * dx + dy * dy);\n  };\n\n  // Setup and cleanup\n  useEffect(() => {\n    const canvas = canvasRef.current;\n    canvas.width = 600;\n    canvas.height = 400;\n    initializeSimulation();\n\n    return () => {\n      if (animationFrameRef.current) {\n        cancelAnimationFrame(animationFrameRef.current);\n      }\n    };\n  }, []);\n\n  useEffect(() => {\n    if (isRunning) {\n      animate();\n    } else if (animationFrameRef.current) {\n      cancelAnimationFrame(animationFrameRef.current);\n    }\n  }, [isRunning]);\n\n  const handleSettingChange = (setting, value) => {\n    setSettings(prev => ({\n      ...prev,\n      [setting]: parseFloat(value)\n    }));\n  };\n\n  return (\n    <div className=\"p-4 space-y-4\">\n      <div className=\"space-y-2\">\n        <h2 className=\"text-xl font-bold\">Multi-Agent Reinforcement Learning Simulation</h2>\n        <Alert>\n          This simulation demonstrates emergent cooperation and competition between agents\n          learning to gather resources while developing communication protocols.\n        </Alert>\n      </div>\n      \n      <div className=\"space-y-4\">\n        <canvas\n          ref={canvasRef}\n          className=\"border border-gray-300 rounded-lg\"\n        />\n        \n        <div className=\"flex gap-4\">\n          <button\n            className=\"px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600\"\n            onClick={() => setIsRunning(!isRunning)}\n          >\n            {isRunning ? 'Pause' : 'Start'}\n          </button>\n          <button\n            className=\"px-4 py-2 bg-gray-500 text-white rounded hover:bg-gray-600\"\n            onClick={initializeSimulation}\n          >\n            Reset\n          </button>\n        </div>\n        \n        <div className=\"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4\">\n          {Object.entries(settings).map(([key, value]) => (\n            <div key={key} className=\"space-y-1\">\n              <label className=\"text-sm font-medium\">\n                {key.split(/(?=[A-Z])/).join(' ')}\n              </label>\n              <input\n                type=\"range\"\n                min={key.includes('Rate') ? 0 : 1}\n                max={key === 'numAgents' ? 50 : \n                     key === 'numResources' ? 100 :\n                     key === 'communicationRange' ? 100 :\n                     key.includes('Rate') ? 1 : 10}\n                step={key.includes('Rate') ? 0.01 : 1}\n                value={value}\n                onChange={(e) => handleSettingChange(key, e.target.value)}\n                className=\"w-full\"\n              />\n              <span className=\"text-sm\">{value}</span>\n            </div>\n          ))}\n        </div>\n\n        {/* Metrics visualization */}\n        <div className=\"space-y-4\">\n          <h3 className=\"text-lg font-semibold\">Learning Progress</h3>\n          <div className=\"h-64\">\n            <LineChart width={600} height={200} data={metrics}>\n              <CartesianGrid strokeDasharray=\"3 3\" />\n              <XAxis dataKey=\"timestamp\" type=\"number\" domain={['auto', 'auto']} />\n              <YAxis />\n              <Tooltip />\n              <Legend />\n              <Line type=\"monotone\" dataKey=\"averageReward\" stroke=\"#8884d8\" name=\"Average Reward\" />\n              <Line type=\"monotone\" dataKey=\"resourceConflicts\" stroke=\"#82ca9d\" name=\"Resource Conflicts\" />\n              <Line type=\"monotone\" dataKey=\"cooperativeActions\" stroke=\"#ffc658\" name=\"Cooperative Actions\" />\n              <Line type=\"monotone\" dataKey=\"messageEntropy\" stroke=\"#ff8042\" name=\"Message Entropy\" />\n            </LineChart>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n\nexport default MARLSimulation;"],"mappings":";AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAC1D,SAASC,KAAK,QAAQ,uBAAuB;AAC7C,SAASC,SAAS,EAAEC,IAAI,EAAEC,KAAK,EAAEC,KAAK,EAAEC,aAAa,EAAEC,OAAO,EAAEC,MAAM,QAAQ,UAAU;;AAExF;AACA,MAAMC,YAAY,CAAC;EACjBC,WAAWA,CAACC,SAAS,EAAEC,UAAU,EAAEC,UAAU,EAAE;IAC7C,IAAI,CAACC,QAAQ,GAAG,IAAIC,KAAK,CAACJ,SAAS,CAAC,CAACK,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAC/C,IAAIF,KAAK,CAACH,UAAU,CAAC,CAACI,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAAMC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAC/D,CAAC;IACD,IAAI,CAACC,QAAQ,GAAG,IAAIL,KAAK,CAACH,UAAU,CAAC,CAACI,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAChD,IAAIF,KAAK,CAACF,UAAU,CAAC,CAACG,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAAMC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAC/D,CAAC;EACH;EAEAE,OAAOA,CAACC,MAAM,EAAE;IACd;IACA,MAAMC,MAAM,GAAGD,MAAM,CAACL,GAAG,CAAC,CAACO,CAAC,EAAEC,CAAC,KAC7B,IAAI,CAACX,QAAQ,CAACW,CAAC,CAAC,CAACC,MAAM,CAAC,CAACC,GAAG,EAAEC,CAAC,EAAEC,CAAC,KAAKF,GAAG,GAAGC,CAAC,GAAGN,MAAM,CAACO,CAAC,CAAC,EAAE,CAAC,CAC/D,CAAC,CAACZ,GAAG,CAACa,CAAC,IAAIZ,IAAI,CAACa,GAAG,CAAC,CAAC,EAAED,CAAC,CAAC,CAAC;IAE1B,MAAME,OAAO,GAAG,IAAI,CAACZ,QAAQ,CAACH,GAAG,CAACgB,GAAG,IACnCV,MAAM,CAACG,MAAM,CAAC,CAACC,GAAG,EAAEO,CAAC,EAAEL,CAAC,KAAKF,GAAG,GAAGO,CAAC,GAAGD,GAAG,CAACJ,CAAC,CAAC,EAAE,CAAC,CAClD,CAAC,CAACZ,GAAG,CAACa,CAAC,IAAI,CAAC,IAAI,CAAC,GAAGZ,IAAI,CAACiB,GAAG,CAAC,CAACL,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;;IAEpC,OAAOE,OAAO;EAChB;AACF;AAEA,MAAMI,KAAK,CAAC;EACV1B,WAAWA,CAACoB,CAAC,EAAEO,CAAC,EAAEC,EAAE,EAAE;IACpB,IAAI,CAACR,CAAC,GAAGA,CAAC;IACV,IAAI,CAACO,CAAC,GAAGA,CAAC;IACV,IAAI,CAACC,EAAE,GAAGA,EAAE;IACZ,IAAI,CAACC,MAAM,GAAG,GAAG;IACjB,IAAI,CAACC,OAAO,GAAG,IAAIzB,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI,CAAC,CAAC,CAAC;IACnC,IAAI,CAACyB,OAAO,GAAG,IAAIhC,YAAY,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;IACzC,IAAI,CAACiC,MAAM,GAAG,CAAC;IACf,IAAI,CAACC,MAAM,GAAG,EAAE;IAChB,IAAI,CAACC,eAAe,GAAG,GAAG,CAAC,CAAC;IAC5B,IAAI,CAACC,EAAE,GAAG,CAAC,CAAC,CAAC;IACb,IAAI,CAACC,EAAE,GAAG,CAAC;IACX,IAAI,CAACC,UAAU,GAAG,IAAI;IACtB,IAAI,CAACC,UAAU,GAAG,CAAC;EACrB;EAEAC,GAAGA,CAACC,KAAK,EAAE;IACT;IACA,IAAIhC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,IAAI,CAACyB,eAAe,EAAE;MACxC,OAAO;QACLO,EAAE,EAAEjC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;QACzBiC,EAAE,EAAElC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC;QACzBkC,MAAM,EAAE,CAACnC,IAAI,CAACC,MAAM,CAAC,CAAC,EAAED,IAAI,CAACC,MAAM,CAAC,CAAC,CAAC;QACtCqB,OAAO,EAAEzB,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI,CAAC,CAAC,CAAC,CAACC,GAAG,CAAC,MAAMC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,CAAC;MACjE,CAAC;IACH;IAEA,MAAMa,OAAO,GAAG,IAAI,CAACS,OAAO,CAACpB,OAAO,CAAC6B,KAAK,CAAC;;IAE3C;IACA,IAAI,CAACL,EAAE,GAAG,CAAC,IAAI,CAACA,EAAE,IAAI,CAAC,IAAI,GAAG,GAAG,CAACb,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,GAAG;IAC3D,IAAI,CAACc,EAAE,GAAG,CAAC,IAAI,CAACA,EAAE,IAAI,CAAC,IAAI,GAAG,GAAG,CAACd,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,GAAG;IAE3D,OAAO;MACLmB,EAAE,EAAE,IAAI,CAACN,EAAE;MACXO,EAAE,EAAE,IAAI,CAACN,EAAE;MACXO,MAAM,EAAErB,OAAO,CAACsB,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;MAC3Bd,OAAO,EAAER,OAAO,CAACsB,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACrC,GAAG,CAACa,CAAC,IAAIA,CAAC,GAAG,GAAG,GAAG,CAAC,GAAG,CAAC;IACvD,CAAC;EACH;EAEAyB,KAAKA,CAACC,UAAU,EAAE;IAChB,MAAM;MAAEN,KAAK;MAAEG,MAAM;MAAEX,MAAM;MAAEe;IAAU,CAAC,GAAGD,UAAU;;IAEvD;IACA,MAAME,YAAY,GAAG,GAAG;IACxB,MAAMC,cAAc,GAAG,IAAI;;IAE3B;IACA,MAAMC,QAAQ,GAAG,IAAI,CAACnB,OAAO,CAACpB,OAAO,CAAC6B,KAAK,CAAC;IAC5C,MAAMW,KAAK,GAAG,IAAI,CAACpB,OAAO,CAACpB,OAAO,CAACoC,SAAS,CAAC;IAC7C,MAAMK,QAAQ,GAAG5C,IAAI,CAACa,GAAG,CAAC,GAAG8B,KAAK,CAAC;IACnC,MAAME,OAAO,GAAGrB,MAAM,GAAGiB,cAAc,GAAGG,QAAQ,GAAGF,QAAQ,CAAC,CAAC,CAAC;;IAEhE;IACA,IAAI,CAAC9C,QAAQ,GAAG,IAAI,CAACA,QAAQ,CAACG,GAAG,CAACgB,GAAG,IACnCA,GAAG,CAAChB,GAAG,CAACW,CAAC,IAAIA,CAAC,GAAG8B,YAAY,GAAGK,OAAO,GAAGb,KAAK,CAAC,CAAC,CAAC,CACpD,CAAC;IACD,IAAI,CAAC9B,QAAQ,GAAG,IAAI,CAACA,QAAQ,CAACH,GAAG,CAACgB,GAAG,IACnCA,GAAG,CAAChB,GAAG,CAACW,CAAC,IAAIA,CAAC,GAAG8B,YAAY,GAAGK,OAAO,GAAGH,QAAQ,CAAC,CAAC,CAAC,CACvD,CAAC;IAED,IAAI,CAAClB,MAAM,IAAIA,MAAM;;IAErB;IACA,IAAI,CAACE,eAAe,IAAI,KAAK;EAC/B;AACF;AAEA,MAAMoB,QAAQ,CAAC;EACbtD,WAAWA,CAACoB,CAAC,EAAEO,CAAC,EAAE4B,KAAK,EAAE;IACvB,IAAI,CAACnC,CAAC,GAAGA,CAAC;IACV,IAAI,CAACO,CAAC,GAAGA,CAAC;IACV,IAAI,CAAC4B,KAAK,GAAGA,KAAK;EACpB;AACF;AAEA,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAC3B,MAAMC,SAAS,GAAGnE,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMoE,SAAS,GAAGpE,MAAM,CAAC,EAAE,CAAC;EAC5B,MAAMqE,YAAY,GAAGrE,MAAM,CAAC,EAAE,CAAC;EAC/B,MAAMsE,iBAAiB,GAAGtE,MAAM,CAAC,IAAI,CAAC;EAEtC,MAAM,CAACuE,SAAS,EAAEC,YAAY,CAAC,GAAG1E,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAAC2E,OAAO,EAAEC,UAAU,CAAC,GAAG5E,QAAQ,CAAC,CAAC;IACtC6E,SAAS,EAAEC,IAAI,CAACC,GAAG,CAAC,CAAC;IACrBC,aAAa,EAAE,CAAC;IAChBC,iBAAiB,EAAE,CAAC;IACpBC,kBAAkB,EAAE,CAAC;IACrBC,cAAc,EAAE;EAClB,CAAC,CAAC,CAAC;EAEH,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGrF,QAAQ,CAAC;IACvCsF,SAAS,EAAE,EAAE;IACbC,YAAY,EAAE,EAAE;IAChB3B,YAAY,EAAE,IAAI;IAClBd,eAAe,EAAE,GAAG;IACpB0C,kBAAkB,EAAE,EAAE;IACtBC,wBAAwB,EAAE;EAC5B,CAAC,CAAC;;EAEF;EACA,MAAMC,oBAAoB,GAAGA,CAAA,KAAM;IACjC,MAAMC,MAAM,GAAGtB,SAAS,CAACuB,OAAO;;IAEhC;IACA,MAAMC,SAAS,GAAG,EAAE;IACpB,KAAK,IAAIlE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyD,QAAQ,CAACE,SAAS,EAAE3D,CAAC,EAAE,EAAE;MAC3CkE,SAAS,CAACC,IAAI,CAAC,IAAIxD,KAAK,CACtBlB,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGsE,MAAM,CAACI,KAAK,EAC5B3E,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGsE,MAAM,CAACK,MAAM,EAC7BrE,CACF,CAAC,CAAC;IACJ;IACA2C,SAAS,CAACsB,OAAO,GAAGC,SAAS;;IAE7B;IACA,MAAMI,YAAY,GAAG,EAAE;IACvB,KAAK,IAAItE,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGyD,QAAQ,CAACG,YAAY,EAAE5D,CAAC,EAAE,EAAE;MAC9CsE,YAAY,CAACH,IAAI,CAAC,IAAI5B,QAAQ,CAC5B9C,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGsE,MAAM,CAACI,KAAK,EAC5B3E,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGsE,MAAM,CAACK,MAAM,EAC7B5E,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EACvB,CAAC,CAAC;IACJ;IACAkD,YAAY,CAACqB,OAAO,GAAGK,YAAY;EACrC,CAAC;;EAED;EACA,MAAMC,aAAa,GAAIC,KAAK,IAAK;IAC/B,MAAMC,eAAe,GAAG7B,YAAY,CAACqB,OAAO,CACzCS,MAAM,CAACC,CAAC,IAAIC,QAAQ,CAACJ,KAAK,EAAEG,CAAC,CAAC,GAAGlB,QAAQ,CAACI,kBAAkB,CAAC,CAC7DhC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CACXrC,GAAG,CAACmF,CAAC,IAAIC,QAAQ,CAACJ,KAAK,EAAEG,CAAC,CAAC,GAAGlB,QAAQ,CAACI,kBAAkB,CAAC;IAE7D,MAAMgB,YAAY,GAAGlC,SAAS,CAACsB,OAAO,CACnCS,MAAM,CAACI,CAAC,IAAIA,CAAC,KAAKN,KAAK,IAAII,QAAQ,CAACJ,KAAK,EAAEM,CAAC,CAAC,GAAGrB,QAAQ,CAACI,kBAAkB,CAAC;IAE/E,MAAMkB,eAAe,GAAGF,YAAY,CAACG,MAAM,GAAG,CAAC,GAC3CH,YAAY,CAAC,CAAC,CAAC,CAAC9D,OAAO,GACvB,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;IAEhB,OAAO,CACLyD,KAAK,CAACnE,CAAC,GAAGqC,SAAS,CAACuB,OAAO,CAACG,KAAK,EACjCI,KAAK,CAAC5D,CAAC,GAAG8B,SAAS,CAACuB,OAAO,CAACI,MAAM,EAClCG,KAAK,CAAC1D,MAAM,GAAG,GAAG,EAClB,GAAG2D,eAAe,EAClB,GAAG,IAAInF,KAAK,CAAC,CAAC,GAAGmF,eAAe,CAACO,MAAM,CAAC,CAACzF,IAAI,CAAC,CAAC,CAAC,EAChD,GAAGwF,eAAe,CACnB;EACH,CAAC;;EAED;EACA,MAAME,gBAAgB,GAAGA,CAAA,KAAM;IAC7B,MAAMjB,MAAM,GAAGtB,SAAS,CAACuB,OAAO;IAChC,MAAMiB,aAAa,GAAGvC,SAAS,CAACsB,OAAO,CAACzE,GAAG,CAACgF,KAAK,IAAI;MACnD,MAAM/C,KAAK,GAAG8C,aAAa,CAACC,KAAK,CAAC;MAClC,MAAM5C,MAAM,GAAG4C,KAAK,CAAChD,GAAG,CAACC,KAAK,CAAC;;MAE/B;MACA,MAAM0D,IAAI,GAAG,CAACX,KAAK,CAACnE,CAAC,GAAGuB,MAAM,CAACF,EAAE,GAAG,CAAC,GAAGsC,MAAM,CAACI,KAAK,IAAIJ,MAAM,CAACI,KAAK;MACpE,MAAMgB,IAAI,GAAG,CAACZ,KAAK,CAAC5D,CAAC,GAAGgB,MAAM,CAACD,EAAE,GAAG,CAAC,GAAGqC,MAAM,CAACK,MAAM,IAAIL,MAAM,CAACK,MAAM;;MAEtE;MACA,MAAMI,eAAe,GAAG7B,YAAY,CAACqB,OAAO,CAACS,MAAM,CAACC,CAAC,IAAIC,QAAQ,CAAC;QAACvE,CAAC,EAAE8E,IAAI;QAAEvE,CAAC,EAAEwE;MAAI,CAAC,EAAET,CAAC,CAAC,GAAG,EAAE,CAAC;MAC9F,IAAI1D,MAAM,GAAG,CAAC;MAEd,IAAIwD,eAAe,CAACO,MAAM,GAAG,CAAC,EAAE;QAC9B,MAAMK,QAAQ,GAAGZ,eAAe,CAAC,CAAC,CAAC;QACnC,MAAMa,eAAe,GAAG3C,SAAS,CAACsB,OAAO,CAACS,MAAM,CAC9CI,CAAC,IAAIA,CAAC,KAAKN,KAAK,IAAII,QAAQ,CAAC;UAACvE,CAAC,EAAE8E,IAAI;UAAEvE,CAAC,EAAEwE;QAAI,CAAC,EAAEC,QAAQ,CAAC,GAAG,EAC/D,CAAC;QAED,IAAIC,eAAe,CAACN,MAAM,GAAG,CAAC,EAAE;UAC9B;UACA,MAAMO,WAAW,GAAGD,eAAe,CAACN,MAAM,GAAG,CAAC;UAC9C/D,MAAM,GAAGoE,QAAQ,CAAC7C,KAAK,GAAG+C,WAAW;;UAErC;UACA,MAAMC,iBAAiB,GAAGF,eAAe,CAACZ,MAAM,CAC9CI,CAAC,IAAIA,CAAC,CAAC/D,OAAO,CAAC0E,IAAI,CAACC,GAAG,IAAIA,GAAG,KAAK,CAAC,CACtC,CAAC;UAED,IAAIF,iBAAiB,CAACR,MAAM,GAAG,CAAC,EAAE;YAChC/D,MAAM,IAAI,GAAG,CAAC,CAAC;UACjB;QACF,CAAC,MAAM;UACLA,MAAM,GAAGoE,QAAQ,CAAC7C,KAAK;QACzB;QAEA6C,QAAQ,CAAC7C,KAAK,IAAK,CAAC,GAAG,GAAI,CAAC,CAAC;QAC7B,IAAI6C,QAAQ,CAAC7C,KAAK,GAAG,EAAE,EAAE;UACvBI,YAAY,CAACqB,OAAO,GAAGrB,YAAY,CAACqB,OAAO,CAACS,MAAM,CAACC,CAAC,IAAIA,CAAC,KAAKU,QAAQ,CAAC;QACzE;MACF;;MAEA;MACAb,KAAK,CAACnE,CAAC,GAAG8E,IAAI;MACdX,KAAK,CAAC5D,CAAC,GAAGwE,IAAI;MACdZ,KAAK,CAAC1D,MAAM,GAAGrB,IAAI,CAACkG,GAAG,CAAC,GAAG,EAAEnB,KAAK,CAAC1D,MAAM,GAAGG,MAAM,CAAC;MACnDuD,KAAK,CAACzD,OAAO,GAAGa,MAAM,CAACb,OAAO;;MAE9B;MACAyD,KAAK,CAAC1C,KAAK,CAAC;QACVL,KAAK;QACLG,MAAM;QACNX,MAAM;QACNe,SAAS,EAAEuC,aAAa,CAACC,KAAK;MAChC,CAAC,CAAC;MAEF,OAAOA,KAAK;IACd,CAAC,CAAC;;IAEF;IACA,IAAI/E,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG+D,QAAQ,CAACK,wBAAwB,IACjDlB,YAAY,CAACqB,OAAO,CAACe,MAAM,GAAGvB,QAAQ,CAACG,YAAY,EAAE;MACvDhB,YAAY,CAACqB,OAAO,CAACE,IAAI,CAAC,IAAI5B,QAAQ,CACpC9C,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGsE,MAAM,CAACI,KAAK,EAC5B3E,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGsE,MAAM,CAACK,MAAM,EAC7B5E,IAAI,CAACC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EACvB,CAAC,CAAC;IACJ;IAEAiD,SAAS,CAACsB,OAAO,GAAGiB,aAAa;;IAEjC;IACA,IAAI/B,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG,EAAE,KAAK,CAAC,EAAE;MACzB,MAAMwC,UAAU,GAAGC,gBAAgB,CAAC,CAAC;MACrC5C,UAAU,CAAC6C,IAAI,IAAI,CAAC,GAAGA,IAAI,CAACjE,KAAK,CAAC,CAAC,EAAE,CAAC,EAAE+D,UAAU,CAAC,CAAC;IACtD;EACF,CAAC;;EAED;EACA,MAAMC,gBAAgB,GAAGA,CAAA,KAAM;IAC7B,MAAME,MAAM,GAAGpD,SAAS,CAACsB,OAAO;;IAEhC;IACA,MAAMZ,aAAa,GAAG0C,MAAM,CAAC9F,MAAM,CAAC,CAACC,GAAG,EAAEsE,KAAK,KAAKtE,GAAG,GAAGsE,KAAK,CAACvD,MAAM,EAAE,CAAC,CAAC,GAAG8E,MAAM,CAACf,MAAM;;IAE1F;IACA,MAAM1B,iBAAiB,GAAGV,YAAY,CAACqB,OAAO,CAAChE,MAAM,CAAC,CAAC+F,KAAK,EAAEX,QAAQ,KAAK;MACzE,MAAMR,YAAY,GAAGkB,MAAM,CAACrB,MAAM,CAACI,CAAC,IAAIF,QAAQ,CAACE,CAAC,EAAEO,QAAQ,CAAC,GAAG,EAAE,CAAC;MACnE,OAAOW,KAAK,IAAInB,YAAY,CAACG,MAAM,GAAG,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IAClD,CAAC,EAAE,CAAC,CAAC;;IAEL;IACA,MAAMzB,kBAAkB,GAAGwC,MAAM,CAAC9F,MAAM,CAAC,CAAC+F,KAAK,EAAExB,KAAK,KAAK;MACzD,MAAMK,YAAY,GAAGkB,MAAM,CAACrB,MAAM,CAACI,CAAC,IAAIA,CAAC,KAAKN,KAAK,IAAII,QAAQ,CAACJ,KAAK,EAAEM,CAAC,CAAC,GAAGrB,QAAQ,CAACI,kBAAkB,CAAC;MACxG,OAAOmC,KAAK,IAAInB,YAAY,CAACY,IAAI,CAACX,CAAC,IAAIA,CAAC,CAAC/D,OAAO,CAAC0E,IAAI,CAACC,GAAG,IAAIA,GAAG,KAAK,CAAC,CAAC,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IACnF,CAAC,EAAE,CAAC,CAAC;;IAEL;IACA,MAAMO,QAAQ,GAAGF,MAAM,CAACvG,GAAG,CAACsF,CAAC,IAAIA,CAAC,CAAC/D,OAAO,CAACmF,IAAI,CAAC,EAAE,CAAC,CAAC;IACpD,MAAMC,WAAW,GAAGF,QAAQ,CAAChG,MAAM,CAAC,CAACmG,IAAI,EAAEC,GAAG,KAAK;MACjDD,IAAI,CAACC,GAAG,CAAC,GAAG,CAACD,IAAI,CAACC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC;MAChC,OAAOD,IAAI;IACb,CAAC,EAAE,CAAC,CAAC,CAAC;IACN,MAAM5C,cAAc,GAAG8C,MAAM,CAACC,MAAM,CAACJ,WAAW,CAAC,CAAClG,MAAM,CAAC,CAACuG,OAAO,EAAEJ,IAAI,KAAK;MAC1E,MAAMK,CAAC,GAAGL,IAAI,GAAGH,QAAQ,CAACjB,MAAM;MAChC,OAAOwB,OAAO,GAAGC,CAAC,GAAGhH,IAAI,CAACiH,IAAI,CAACD,CAAC,CAAC;IACnC,CAAC,EAAE,CAAC,CAAC;IAEL,OAAO;MACLvD,SAAS,EAAEC,IAAI,CAACC,GAAG,CAAC,CAAC;MACrBC,aAAa;MACbC,iBAAiB;MACjBC,kBAAkB;MAClBC;IACF,CAAC;EACH,CAAC;;EAED;EACA,MAAMmD,OAAO,GAAGA,CAAA,KAAM;IACpB,IAAI,CAAC7D,SAAS,EAAE;IAEhB,MAAMkB,MAAM,GAAGtB,SAAS,CAACuB,OAAO;IAChC,MAAM2C,GAAG,GAAG5C,MAAM,CAAC6C,UAAU,CAAC,IAAI,CAAC;;IAEnC;IACAD,GAAG,CAACE,SAAS,GAAG,SAAS;IACzBF,GAAG,CAACG,QAAQ,CAAC,CAAC,EAAE,CAAC,EAAE/C,MAAM,CAACI,KAAK,EAAEJ,MAAM,CAACK,MAAM,CAAC;;IAE/C;IACAzB,YAAY,CAACqB,OAAO,CAAC+C,OAAO,CAAC3B,QAAQ,IAAI;MACvCuB,GAAG,CAACE,SAAS,GAAG,QAAQzB,QAAQ,CAAC7C,KAAK,kBAAkB;MACxDoE,GAAG,CAACK,SAAS,CAAC,CAAC;MACfL,GAAG,CAACM,GAAG,CAAC7B,QAAQ,CAAChF,CAAC,EAAEgF,QAAQ,CAACzE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAEnB,IAAI,CAAC0H,EAAE,GAAG,CAAC,CAAC;MAClDP,GAAG,CAACrH,IAAI,CAAC,CAAC;IACZ,CAAC,CAAC;;IAEF;IACAoD,SAAS,CAACsB,OAAO,CAAC+C,OAAO,CAACxC,KAAK,IAAI;MACjC;MACAoC,GAAG,CAACE,SAAS,GAAG,OAAOtC,KAAK,CAAC3D,EAAE,GAAG,KAAK,GAAG,GAAG,aAAa;MAC1D+F,GAAG,CAACK,SAAS,CAAC,CAAC;MACfL,GAAG,CAACM,GAAG,CAAC1C,KAAK,CAACnE,CAAC,EAAEmE,KAAK,CAAC5D,CAAC,EAAE,CAAC,EAAE,CAAC,EAAEnB,IAAI,CAAC0H,EAAE,GAAG,CAAC,CAAC;MAC5CP,GAAG,CAACrH,IAAI,CAAC,CAAC;;MAEV;MACA,IAAIiF,KAAK,CAACzD,OAAO,CAAC0E,IAAI,CAACC,GAAG,IAAIA,GAAG,KAAK,CAAC,CAAC,EAAE;QACxCkB,GAAG,CAACQ,WAAW,GAAG,QAAQ5C,KAAK,CAAC3D,EAAE,GAAG,KAAK,GAAG,GAAG,kBAAkB;QAClE+F,GAAG,CAACK,SAAS,CAAC,CAAC;QACfL,GAAG,CAACM,GAAG,CAAC1C,KAAK,CAACnE,CAAC,EAAEmE,KAAK,CAAC5D,CAAC,EAAE6C,QAAQ,CAACI,kBAAkB,EAAE,CAAC,EAAEpE,IAAI,CAAC0H,EAAE,GAAG,CAAC,CAAC;QACtEP,GAAG,CAACS,MAAM,CAAC,CAAC;MACd;IACF,CAAC,CAAC;;IAEF;IACApC,gBAAgB,CAAC,CAAC;IAElBpC,iBAAiB,CAACoB,OAAO,GAAGqD,qBAAqB,CAACX,OAAO,CAAC;EAC5D,CAAC;;EAED;EACA,MAAM/B,QAAQ,GAAGA,CAAC2C,EAAE,EAAEC,EAAE,KAAK;IAC3B,MAAM9F,EAAE,GAAG8F,EAAE,CAACnH,CAAC,GAAGkH,EAAE,CAAClH,CAAC;IACtB,MAAMsB,EAAE,GAAG6F,EAAE,CAAC5G,CAAC,GAAG2G,EAAE,CAAC3G,CAAC;IACtB,OAAOnB,IAAI,CAACgI,IAAI,CAAC/F,EAAE,GAAGA,EAAE,GAAGC,EAAE,GAAGA,EAAE,CAAC;EACrC,CAAC;;EAED;EACArD,SAAS,CAAC,MAAM;IACd,MAAM0F,MAAM,GAAGtB,SAAS,CAACuB,OAAO;IAChCD,MAAM,CAACI,KAAK,GAAG,GAAG;IAClBJ,MAAM,CAACK,MAAM,GAAG,GAAG;IACnBN,oBAAoB,CAAC,CAAC;IAEtB,OAAO,MAAM;MACX,IAAIlB,iBAAiB,CAACoB,OAAO,EAAE;QAC7ByD,oBAAoB,CAAC7E,iBAAiB,CAACoB,OAAO,CAAC;MACjD;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN3F,SAAS,CAAC,MAAM;IACd,IAAIwE,SAAS,EAAE;MACb6D,OAAO,CAAC,CAAC;IACX,CAAC,MAAM,IAAI9D,iBAAiB,CAACoB,OAAO,EAAE;MACpCyD,oBAAoB,CAAC7E,iBAAiB,CAACoB,OAAO,CAAC;IACjD;EACF,CAAC,EAAE,CAACnB,SAAS,CAAC,CAAC;EAEf,MAAM6E,mBAAmB,GAAGA,CAACC,OAAO,EAAEpF,KAAK,KAAK;IAC9CkB,WAAW,CAACoC,IAAI,KAAK;MACnB,GAAGA,IAAI;MACP,CAAC8B,OAAO,GAAGC,UAAU,CAACrF,KAAK;IAC7B,CAAC,CAAC,CAAC;EACL,CAAC;EAED,oBACEpE,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,eAAe;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAC5BjK,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACxBjK,KAAA,CAAA0J,aAAA;IAAIC,SAAS,EAAC,mBAAmB;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAC,+CAAiD,CAAC,eACpFjK,KAAA,CAAA0J,aAAA,CAACtJ,KAAK;IAAAwJ,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAC,yJAGA,CACJ,CAAC,eAENjK,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACxBjK,KAAA,CAAA0J,aAAA;IACEQ,GAAG,EAAE5F,SAAU;IACfqF,SAAS,EAAC,mCAAmC;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAC9C,CAAC,eAEFjK,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,YAAY;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACzBjK,KAAA,CAAA0J,aAAA;IACEC,SAAS,EAAC,4DAA4D;IACtEQ,OAAO,EAAEA,CAAA,KAAMxF,YAAY,CAAC,CAACD,SAAS,CAAE;IAAAkF,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAEvCvF,SAAS,GAAG,OAAO,GAAG,OACjB,CAAC,eACT1E,KAAA,CAAA0J,aAAA;IACEC,SAAS,EAAC,4DAA4D;IACtEQ,OAAO,EAAExE,oBAAqB;IAAAiE,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAC/B,OAEO,CACL,CAAC,eAENjK,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,sDAAsD;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAClE/B,MAAM,CAACkC,OAAO,CAAC/E,QAAQ,CAAC,CAACjE,GAAG,CAAC,CAAC,CAACiJ,GAAG,EAAEjG,KAAK,CAAC,kBACzCpE,KAAA,CAAA0J,aAAA;IAAKW,GAAG,EAAEA,GAAI;IAACV,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAClCjK,KAAA,CAAA0J,aAAA;IAAOC,SAAS,EAAC,qBAAqB;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GACnCI,GAAG,CAACC,KAAK,CAAC,WAAW,CAAC,CAACxC,IAAI,CAAC,GAAG,CAC3B,CAAC,eACR9H,KAAA,CAAA0J,aAAA;IACEa,IAAI,EAAC,OAAO;IACZhD,GAAG,EAAE8C,GAAG,CAACG,QAAQ,CAAC,MAAM,CAAC,GAAG,CAAC,GAAG,CAAE;IAClCtI,GAAG,EAAEmI,GAAG,KAAK,WAAW,GAAG,EAAE,GACxBA,GAAG,KAAK,cAAc,GAAG,GAAG,GAC5BA,GAAG,KAAK,oBAAoB,GAAG,GAAG,GAClCA,GAAG,CAACG,QAAQ,CAAC,MAAM,CAAC,GAAG,CAAC,GAAG,EAAG;IACnCC,IAAI,EAAEJ,GAAG,CAACG,QAAQ,CAAC,MAAM,CAAC,GAAG,IAAI,GAAG,CAAE;IACtCpG,KAAK,EAAEA,KAAM;IACbsG,QAAQ,EAAGC,CAAC,IAAKpB,mBAAmB,CAACc,GAAG,EAAEM,CAAC,CAACC,MAAM,CAACxG,KAAK,CAAE;IAC1DuF,SAAS,EAAC,QAAQ;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CACnB,CAAC,eACFjK,KAAA,CAAA0J,aAAA;IAAMC,SAAS,EAAC,SAAS;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAE7F,KAAY,CACpC,CACN,CACE,CAAC,eAGNpE,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,WAAW;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACxBjK,KAAA,CAAA0J,aAAA;IAAIC,SAAS,EAAC,uBAAuB;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,GAAC,mBAAqB,CAAC,eAC5DjK,KAAA,CAAA0J,aAAA;IAAKC,SAAS,EAAC,MAAM;IAAAC,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBACnBjK,KAAA,CAAA0J,aAAA,CAACrJ,SAAS;IAAC2F,KAAK,EAAE,GAAI;IAACC,MAAM,EAAE,GAAI;IAAC4E,IAAI,EAAEjG,OAAQ;IAAAgF,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,gBAChDjK,KAAA,CAAA0J,aAAA,CAACjJ,aAAa;IAACqK,eAAe,EAAC,KAAK;IAAAlB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACvCjK,KAAA,CAAA0J,aAAA,CAACnJ,KAAK;IAACwK,OAAO,EAAC,WAAW;IAACR,IAAI,EAAC,QAAQ;IAACS,MAAM,EAAE,CAAC,MAAM,EAAE,MAAM,CAAE;IAAApB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACrEjK,KAAA,CAAA0J,aAAA,CAAClJ,KAAK;IAAAoJ,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACTjK,KAAA,CAAA0J,aAAA,CAAChJ,OAAO;IAAAkJ,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACXjK,KAAA,CAAA0J,aAAA,CAAC/I,MAAM;IAAAiJ,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACVjK,KAAA,CAAA0J,aAAA,CAACpJ,IAAI;IAACiK,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,eAAe;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,gBAAgB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACvFjK,KAAA,CAAA0J,aAAA,CAACpJ,IAAI;IAACiK,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,mBAAmB;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,oBAAoB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eAC/FjK,KAAA,CAAA0J,aAAA,CAACpJ,IAAI;IAACiK,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,oBAAoB;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,qBAAqB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAAC,eACjGjK,KAAA,CAAA0J,aAAA,CAACpJ,IAAI;IAACiK,IAAI,EAAC,UAAU;IAACQ,OAAO,EAAC,gBAAgB;IAAC9B,MAAM,EAAC,SAAS;IAACgC,IAAI,EAAC,iBAAiB;IAAArB,MAAA;IAAAC,QAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EAAA,CAAE,CAC/E,CACR,CACF,CACF,CACF,CAAC;AAEV,CAAC;AAED,eAAe5F,cAAc","ignoreList":[]},"metadata":{},"sourceType":"module"}